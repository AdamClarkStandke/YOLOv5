{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1r9UpmUHhGSCdstpooQhpvd-GiubuBqw4",
      "authorship_tag": "ABX9TyOZpCsZZtinbatpwW/t/lps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a6417c4f6ea4447b2e2a353da394dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b75cb1f5af2434fa5602c931538d8bb",
              "IPY_MODEL_33a4ca1c34ea4ae3a58a768875a8d39d",
              "IPY_MODEL_809b5578dca04d078ecebd4da1dbc7d5"
            ],
            "layout": "IPY_MODEL_c6145fa4a0cb4147a13553c8aa929a84"
          }
        },
        "9b75cb1f5af2434fa5602c931538d8bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3322f1bbb91d4f31b591d4fbf1ec78f5",
            "placeholder": "​",
            "style": "IPY_MODEL_0bf1735155eb460390f83d888808a8c2",
            "value": "modules.json: 100%"
          }
        },
        "33a4ca1c34ea4ae3a58a768875a8d39d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_551dd64a0294485395b82eaa876fecc5",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0453df6ab4fd4bf49b24fab950fca8ca",
            "value": 349
          }
        },
        "809b5578dca04d078ecebd4da1dbc7d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f3f382745574c5ebb7a10f7f3c6b679",
            "placeholder": "​",
            "style": "IPY_MODEL_d469ac2406f14404b0b8ffd3dabad042",
            "value": " 349/349 [00:00&lt;00:00, 635B/s]"
          }
        },
        "c6145fa4a0cb4147a13553c8aa929a84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3322f1bbb91d4f31b591d4fbf1ec78f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf1735155eb460390f83d888808a8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "551dd64a0294485395b82eaa876fecc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0453df6ab4fd4bf49b24fab950fca8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f3f382745574c5ebb7a10f7f3c6b679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d469ac2406f14404b0b8ffd3dabad042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a66f9e2f488746588882d8259f4ad507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a2a02b6734045d689803d2b4a49ef40",
              "IPY_MODEL_85f9b0990e7441a8a5410a0595a4de98",
              "IPY_MODEL_36c087eb62ba450398a1928159687992"
            ],
            "layout": "IPY_MODEL_d8c7a0e117c04767adef43fa598ebe80"
          }
        },
        "6a2a02b6734045d689803d2b4a49ef40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c94f56e656294ad0b9ca8bd2e233bba8",
            "placeholder": "​",
            "style": "IPY_MODEL_c4cb24dcad2344a280d4d2065708fc94",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "85f9b0990e7441a8a5410a0595a4de98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dbc49ce38e3482fb6ae5a3d1a6117d9",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6184c8281aec47e4ab839ac57ee43acd",
            "value": 116
          }
        },
        "36c087eb62ba450398a1928159687992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb989689f33049128e71e43b9c96769c",
            "placeholder": "​",
            "style": "IPY_MODEL_969fbbad4c5240c084d5e921e58d1ffb",
            "value": " 116/116 [00:00&lt;00:00, 438B/s]"
          }
        },
        "d8c7a0e117c04767adef43fa598ebe80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c94f56e656294ad0b9ca8bd2e233bba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4cb24dcad2344a280d4d2065708fc94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dbc49ce38e3482fb6ae5a3d1a6117d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6184c8281aec47e4ab839ac57ee43acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb989689f33049128e71e43b9c96769c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "969fbbad4c5240c084d5e921e58d1ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0f0cdb2f3154b759d65609c85038076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cff14181da4f49d9963876f4538574fd",
              "IPY_MODEL_858bdccbae4d487a852add771fc3c534",
              "IPY_MODEL_a12f1b07a85d46dbb9746e8648f2bb70"
            ],
            "layout": "IPY_MODEL_801dab09da6a44f6a27474c2d44a7936"
          }
        },
        "cff14181da4f49d9963876f4538574fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c692bb2c6c146f29be6398ccaa16316",
            "placeholder": "​",
            "style": "IPY_MODEL_66e358059d9d450b8d1e9670579dc502",
            "value": "README.md: 100%"
          }
        },
        "858bdccbae4d487a852add771fc3c534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f99a424d87e4420d988c660debc208c7",
            "max": 10621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7490322b7334b0f843c7a01abca9372",
            "value": 10621
          }
        },
        "a12f1b07a85d46dbb9746e8648f2bb70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db889b10d69c47709ae8347394b71f4e",
            "placeholder": "​",
            "style": "IPY_MODEL_5cfccdeb41124f2690441fa7da6d8b9e",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 733kB/s]"
          }
        },
        "801dab09da6a44f6a27474c2d44a7936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c692bb2c6c146f29be6398ccaa16316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e358059d9d450b8d1e9670579dc502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f99a424d87e4420d988c660debc208c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7490322b7334b0f843c7a01abca9372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db889b10d69c47709ae8347394b71f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cfccdeb41124f2690441fa7da6d8b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "330757c735d2403e98c52db28a04b151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ae234eadc8548cbb2a5bc93f2f626c2",
              "IPY_MODEL_fb2f58b1c5f548caacb88caf71477fd5",
              "IPY_MODEL_dc27fb4c84be4f659fdf14eeeade184f"
            ],
            "layout": "IPY_MODEL_e0ff3536e512413f85bcd7af765b532f"
          }
        },
        "1ae234eadc8548cbb2a5bc93f2f626c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a36d2e8c20045f88759976c25ef8fc3",
            "placeholder": "​",
            "style": "IPY_MODEL_e0f6180f2594400fa22d476ae53964ac",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "fb2f58b1c5f548caacb88caf71477fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efe3d91cd06e4cf78be930e07ce5045e",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff7eae20b31549eeac225dd6ea2b2963",
            "value": 53
          }
        },
        "dc27fb4c84be4f659fdf14eeeade184f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37a93d81cf834fa7bd04cf1664f32192",
            "placeholder": "​",
            "style": "IPY_MODEL_d10a5952d2084d0993d0d64901518a55",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.93kB/s]"
          }
        },
        "e0ff3536e512413f85bcd7af765b532f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a36d2e8c20045f88759976c25ef8fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f6180f2594400fa22d476ae53964ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efe3d91cd06e4cf78be930e07ce5045e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff7eae20b31549eeac225dd6ea2b2963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37a93d81cf834fa7bd04cf1664f32192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d10a5952d2084d0993d0d64901518a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44fcf2dd88f44e3ebae22ec6dcf09867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_447e4b173cb24711875c96179831d72d",
              "IPY_MODEL_40ea3cac3da64ba18d0397ab577a8ef6",
              "IPY_MODEL_6c3b82fd9ced48f9a0a6284c40f3b8c2"
            ],
            "layout": "IPY_MODEL_e0e3491b66c2400f8d3776ca0448bc6b"
          }
        },
        "447e4b173cb24711875c96179831d72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_693d7f049ceb4e16a167d5b75ade2230",
            "placeholder": "​",
            "style": "IPY_MODEL_127264cd65754a09b9d85552fd9f7734",
            "value": "config.json: 100%"
          }
        },
        "40ea3cac3da64ba18d0397ab577a8ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aad639a43c34969936b7bbc131dd95b",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9d3e19e9dd8492b9e5d6a2fab4c644f",
            "value": 571
          }
        },
        "6c3b82fd9ced48f9a0a6284c40f3b8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1190e31bced045daae3189e3df36f5c4",
            "placeholder": "​",
            "style": "IPY_MODEL_d996897185084c28ac9659e1d3f18cb3",
            "value": " 571/571 [00:00&lt;00:00, 41.2kB/s]"
          }
        },
        "e0e3491b66c2400f8d3776ca0448bc6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "693d7f049ceb4e16a167d5b75ade2230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127264cd65754a09b9d85552fd9f7734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aad639a43c34969936b7bbc131dd95b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9d3e19e9dd8492b9e5d6a2fab4c644f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1190e31bced045daae3189e3df36f5c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d996897185084c28ac9659e1d3f18cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75f7c9e75f7c495b96dbf09352b44085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c35616c02a8f4aa999be23285711374c",
              "IPY_MODEL_a7611be2672348ae9d974494b025655f",
              "IPY_MODEL_71112178e84e4445bc9a676eb7b03b64"
            ],
            "layout": "IPY_MODEL_4ae986132a41446ca4ccc456ed514679"
          }
        },
        "c35616c02a8f4aa999be23285711374c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4259c392011c4f0f9f37ff607c23b402",
            "placeholder": "​",
            "style": "IPY_MODEL_4ef29d21cdb741f583853a1e7c0df34a",
            "value": "model.safetensors: 100%"
          }
        },
        "a7611be2672348ae9d974494b025655f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_108905633bad438f9d1c56d3d59ada66",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_066549e4baac4a0f971aab475e5d8126",
            "value": 437971872
          }
        },
        "71112178e84e4445bc9a676eb7b03b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_998ab6830a1d4ff6abaaca8c4bfe5f32",
            "placeholder": "​",
            "style": "IPY_MODEL_c2efeb16676f4175b69f87caab74d404",
            "value": " 438M/438M [00:02&lt;00:00, 220MB/s]"
          }
        },
        "4ae986132a41446ca4ccc456ed514679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4259c392011c4f0f9f37ff607c23b402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef29d21cdb741f583853a1e7c0df34a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "108905633bad438f9d1c56d3d59ada66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "066549e4baac4a0f971aab475e5d8126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "998ab6830a1d4ff6abaaca8c4bfe5f32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2efeb16676f4175b69f87caab74d404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e958d30446948c0aa4592905da7aad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c22864432490410582f8beff000063c4",
              "IPY_MODEL_1110f78e69ac4523a5e09c977b689b1b",
              "IPY_MODEL_7c823d1d7e82416d9d522bd4ee0609c1"
            ],
            "layout": "IPY_MODEL_8fb0dc99be044b7aae6232e187489062"
          }
        },
        "c22864432490410582f8beff000063c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19f2dea97d874635ab264649c4f33156",
            "placeholder": "​",
            "style": "IPY_MODEL_4b08bd8951724b17a149797bb52dd426",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1110f78e69ac4523a5e09c977b689b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c02224d1ecaa47eabcffc06d2e76a4b4",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9361f1a372ba41d498f274797cb4418e",
            "value": 363
          }
        },
        "7c823d1d7e82416d9d522bd4ee0609c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13acbd27c78041edb9548435bb60d757",
            "placeholder": "​",
            "style": "IPY_MODEL_afc58d36fd614928aaa1d5c379a2387e",
            "value": " 363/363 [00:00&lt;00:00, 31.3kB/s]"
          }
        },
        "8fb0dc99be044b7aae6232e187489062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f2dea97d874635ab264649c4f33156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b08bd8951724b17a149797bb52dd426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c02224d1ecaa47eabcffc06d2e76a4b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9361f1a372ba41d498f274797cb4418e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13acbd27c78041edb9548435bb60d757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc58d36fd614928aaa1d5c379a2387e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "542702ed1b5142a0a8ff0f4d5a9f1bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f684afab0954c76b5c5795ca28e9d95",
              "IPY_MODEL_0c4ffbb402b64796b5e03c069868faa6",
              "IPY_MODEL_db37a114c7ec45ff9106fd9eb32ba4e9"
            ],
            "layout": "IPY_MODEL_231c5291ab4e4dbda1348daf839e4b3e"
          }
        },
        "9f684afab0954c76b5c5795ca28e9d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7575b8060e64b42a8664f26e23f3099",
            "placeholder": "​",
            "style": "IPY_MODEL_01a62b01a55442b5875a75e2283005e4",
            "value": "vocab.txt: 100%"
          }
        },
        "0c4ffbb402b64796b5e03c069868faa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95891f421ea94f79ad7027c2e690c074",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ade4d084c1d4f6fa81e2c0a0c255e57",
            "value": 231536
          }
        },
        "db37a114c7ec45ff9106fd9eb32ba4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521d451cd7f64eebb38ac40c364a5a8b",
            "placeholder": "​",
            "style": "IPY_MODEL_b54bf69607124043af90c6f0ea00ceeb",
            "value": " 232k/232k [00:00&lt;00:00, 4.16MB/s]"
          }
        },
        "231c5291ab4e4dbda1348daf839e4b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7575b8060e64b42a8664f26e23f3099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01a62b01a55442b5875a75e2283005e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95891f421ea94f79ad7027c2e690c074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ade4d084c1d4f6fa81e2c0a0c255e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "521d451cd7f64eebb38ac40c364a5a8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b54bf69607124043af90c6f0ea00ceeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b468c5bc5ca44eef92a9863b663030e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d01f4d455b854109b42419f9f6175911",
              "IPY_MODEL_35f22e400bbe4c29b11a20cb31068b9f",
              "IPY_MODEL_6f77ff91831a4bc2910c7602cf34d540"
            ],
            "layout": "IPY_MODEL_27fb543bbc5a439c997f5b5354e4976b"
          }
        },
        "d01f4d455b854109b42419f9f6175911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac374e4ff8764962a5afa38f52aabc47",
            "placeholder": "​",
            "style": "IPY_MODEL_edc3c0f8436a4088a14969fb5b126178",
            "value": "tokenizer.json: 100%"
          }
        },
        "35f22e400bbe4c29b11a20cb31068b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a485ac8725bb44f6a67a695954c659af",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24657e3de7184db5a001a149d465674c",
            "value": 466021
          }
        },
        "6f77ff91831a4bc2910c7602cf34d540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8006f0c6ec1148c9965302180fa9fff0",
            "placeholder": "​",
            "style": "IPY_MODEL_2fabaf02e1bf4e85af1b025474ff10d9",
            "value": " 466k/466k [00:00&lt;00:00, 21.1MB/s]"
          }
        },
        "27fb543bbc5a439c997f5b5354e4976b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac374e4ff8764962a5afa38f52aabc47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc3c0f8436a4088a14969fb5b126178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a485ac8725bb44f6a67a695954c659af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24657e3de7184db5a001a149d465674c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8006f0c6ec1148c9965302180fa9fff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fabaf02e1bf4e85af1b025474ff10d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f8a5561cd7f47bfbe0c921d707bb7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bda2c275ae64ca48db868e4a9dac694",
              "IPY_MODEL_54426992ffec4c48ab5697175fc0705f",
              "IPY_MODEL_3e1d5a7351fc40a18f5cb40aad865985"
            ],
            "layout": "IPY_MODEL_e903cb5efc1343e0b002663249ec4696"
          }
        },
        "3bda2c275ae64ca48db868e4a9dac694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10cb6c7687c54adfb1976d2347b70926",
            "placeholder": "​",
            "style": "IPY_MODEL_89fddbbce6e04482b356441d3904c3b7",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "54426992ffec4c48ab5697175fc0705f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d8b0f2a26af476f95018cc82c7d3329",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ed29c54f1334687bf3adf02eb94655c",
            "value": 239
          }
        },
        "3e1d5a7351fc40a18f5cb40aad865985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa4098466a3943599c18ca31b5a643fd",
            "placeholder": "​",
            "style": "IPY_MODEL_5a73e36f8cf2493ba6f42c65433966cf",
            "value": " 239/239 [00:00&lt;00:00, 17.8kB/s]"
          }
        },
        "e903cb5efc1343e0b002663249ec4696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10cb6c7687c54adfb1976d2347b70926": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89fddbbce6e04482b356441d3904c3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d8b0f2a26af476f95018cc82c7d3329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed29c54f1334687bf3adf02eb94655c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa4098466a3943599c18ca31b5a643fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a73e36f8cf2493ba6f42c65433966cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e8e70bc5a774228ac5f2d657b483f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c06d73103f434024ae23a8f4e720a9da",
              "IPY_MODEL_94c813d5e8064669a996075ad09d5659",
              "IPY_MODEL_5e5cf40a7ece45f28f446e218eaed0c3"
            ],
            "layout": "IPY_MODEL_7670934882ec4cd3acf4936162eb2107"
          }
        },
        "c06d73103f434024ae23a8f4e720a9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb5d8f0b4164cbfbd7e64635864aaaf",
            "placeholder": "​",
            "style": "IPY_MODEL_0af84b372fbb4565af809513c6eeb478",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "94c813d5e8064669a996075ad09d5659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec0cc4bd7d6f4031b5c74e6d12c340f8",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbf421555bdb48b4b2e0ae486902b38a",
            "value": 190
          }
        },
        "5e5cf40a7ece45f28f446e218eaed0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75e3b3bbae0c4e97bc6b5ae12ac3d67e",
            "placeholder": "​",
            "style": "IPY_MODEL_c8a9a007f53a4644a7933c7ea003be96",
            "value": " 190/190 [00:00&lt;00:00, 256B/s]"
          }
        },
        "7670934882ec4cd3acf4936162eb2107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bb5d8f0b4164cbfbd7e64635864aaaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0af84b372fbb4565af809513c6eeb478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec0cc4bd7d6f4031b5c74e6d12c340f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf421555bdb48b4b2e0ae486902b38a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75e3b3bbae0c4e97bc6b5ae12ac3d67e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8a9a007f53a4644a7933c7ea003be96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamClarkStandke/YOLOv5/blob/main/InteractivePDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WpKprRqC9-_E"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install -qU \"langchain-chroma>=0.1.2\"\n",
        "!pip install langchain-huggingface\n",
        "!pip install langchain-community\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain_chroma import Chroma\n",
        "import getpass\n",
        "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "cYy1pleS_bfN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(HuggingFaceEndpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mLg4lMlAXlt",
        "outputId": "0e0adb2c-5c1c-4d09-9cba-82bed7ac8d5c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class HuggingFaceEndpoint in module langchain_huggingface.llms.huggingface_endpoint:\n",
            "\n",
            "class HuggingFaceEndpoint(langchain_core.language_models.llms.LLM)\n",
            " |  HuggingFaceEndpoint(*args: Any, name: Optional[str] = None, cache: ForwardRef('Union[BaseCache, bool, None]') = None, verbose: bool = None, callbacks: ForwardRef('Callbacks') = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, custom_get_token_ids: Optional[Callable[[str], List[int]]] = None, callback_manager: Optional[langchain_core.callbacks.base.BaseCallbackManager] = None, endpoint_url: Optional[str] = None, repo_id: Optional[str] = None, huggingfacehub_api_token: Optional[str] = None, max_new_tokens: int = 512, top_k: Optional[int] = None, top_p: Optional[float] = 0.95, typical_p: Optional[float] = 0.95, temperature: Optional[float] = 0.8, repetition_penalty: Optional[float] = None, return_full_text: bool = False, truncate: Optional[int] = None, stop_sequences: List[str] = None, seed: Optional[int] = None, inference_server_url: str = '', timeout: int = 120, streaming: bool = False, do_sample: bool = False, watermark: bool = False, server_kwargs: Dict[str, Any] = None, model_kwargs: Dict[str, Any] = None, model: str, client: Any = None, async_client: Any = None, task: Optional[str] = None) -> None\n",
            " |  \n",
            " |  HuggingFace Endpoint.\n",
            " |  \n",
            " |  To use this class, you should have installed the ``huggingface_hub`` package, and\n",
            " |  the environment variable ``HUGGINGFACEHUB_API_TOKEN`` set with your API token,\n",
            " |  or given as a named parameter to the constructor.\n",
            " |  \n",
            " |  Example:\n",
            " |      .. code-block:: python\n",
            " |  \n",
            " |          # Basic Example (no streaming)\n",
            " |          llm = HuggingFaceEndpoint(\n",
            " |              endpoint_url=\"http://localhost:8010/\",\n",
            " |              max_new_tokens=512,\n",
            " |              top_k=10,\n",
            " |              top_p=0.95,\n",
            " |              typical_p=0.95,\n",
            " |              temperature=0.01,\n",
            " |              repetition_penalty=1.03,\n",
            " |              huggingfacehub_api_token=\"my-api-key\"\n",
            " |          )\n",
            " |          print(llm.invoke(\"What is Deep Learning?\"))\n",
            " |  \n",
            " |          # Streaming response example\n",
            " |          from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
            " |  \n",
            " |          callbacks = [StreamingStdOutCallbackHandler()]\n",
            " |          llm = HuggingFaceEndpoint(\n",
            " |              endpoint_url=\"http://localhost:8010/\",\n",
            " |              max_new_tokens=512,\n",
            " |              top_k=10,\n",
            " |              top_p=0.95,\n",
            " |              typical_p=0.95,\n",
            " |              temperature=0.01,\n",
            " |              repetition_penalty=1.03,\n",
            " |              callbacks=callbacks,\n",
            " |              streaming=True,\n",
            " |              huggingfacehub_api_token=\"my-api-key\"\n",
            " |          )\n",
            " |          print(llm.invoke(\"What is Deep Learning?\"))\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      HuggingFaceEndpoint\n",
            " |      langchain_core.language_models.llms.LLM\n",
            " |      langchain_core.language_models.llms.BaseLLM\n",
            " |      langchain_core.language_models.base.BaseLanguageModel\n",
            " |      langchain_core.runnables.base.RunnableSerializable\n",
            " |      langchain_core.load.serializable.Serializable\n",
            " |      pydantic.v1.main.BaseModel\n",
            " |      pydantic.v1.utils.Representation\n",
            " |      langchain_core.runnables.base.Runnable\n",
            " |      typing.Generic\n",
            " |      abc.ABC\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  build_extra(values: Dict[str, Any]) -> Dict[str, Any] from pydantic.v1.main.ModelMetaclass\n",
            " |      Build extra kwargs from additional params that were passed in.\n",
            " |  \n",
            " |  validate_environment(values: Dict) -> Dict from pydantic.v1.main.ModelMetaclass\n",
            " |      Validate that package is installed and that the API token is valid.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  Config = <class 'langchain_huggingface.llms.huggingface_endpoint.Huggi...\n",
            " |      Configuration for this pydantic object.\n",
            " |  \n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  __annotations__ = {'async_client': typing.Any, 'client': typing.Any, '...\n",
            " |  \n",
            " |  __class_vars__ = set()\n",
            " |  \n",
            " |  __config__ = <class 'pydantic.v1.config.Config'>\n",
            " |  \n",
            " |  __custom_root_type__ = False\n",
            " |  \n",
            " |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'cu...\n",
            " |  \n",
            " |  __fields__ = {'async_client': ModelField(name='async_client', type=Opt...\n",
            " |  \n",
            " |  __hash__ = None\n",
            " |  \n",
            " |  __include_fields__ = None\n",
            " |  \n",
            " |  __parameters__ = ()\n",
            " |  \n",
            " |  __post_root_validators__ = [(False, <function HuggingFaceEndpoint.vali...\n",
            " |  \n",
            " |  __pre_root_validators__ = [<function BaseLLM.raise_deprecation>, <func...\n",
            " |  \n",
            " |  __private_attributes__ = {}\n",
            " |  \n",
            " |  __schema_cache__ = {}\n",
            " |  \n",
            " |  __signature__ = <Signature (*args: Any, name: Optional[str] = No... An...\n",
            " |  \n",
            " |  __validators__ = {'verbose': [<pydantic.v1.class_validators.Validator ...\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from langchain_core.language_models.llms.BaseLLM:\n",
            " |  \n",
            " |  __call__(self, prompt: 'str', stop: 'Optional[List[str]]' = None, callbacks: 'Callbacks' = None, *, tags: 'Optional[List[str]]' = None, metadata: 'Optional[Dict[str, Any]]' = None, **kwargs: 'Any') -> 'str'\n",
            " |      .. deprecated:: langchain-core==0.1.7 Use ``invoke`` instead.\n",
            " |      \n",
            " |      Check Cache and run the LLM on the given prompt and input.\n",
            " |      \n",
            " |      Args:\n",
            " |          prompt: The prompt to generate from.\n",
            " |          stop: Stop words to use when generating. Model output is cut off at the\n",
            " |              first occurrence of any of these substrings.\n",
            " |          callbacks: Callbacks to pass through. Used for executing additional\n",
            " |              functionality, such as logging or streaming, throughout generation.\n",
            " |          tags: List of tags to associate with the prompt.\n",
            " |          metadata: Metadata to associate with the prompt.\n",
            " |          **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
            " |              to the model provider API call.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The generated text.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: If the prompt is not a string.\n",
            " |  \n",
            " |  __str__(self) -> 'str'\n",
            " |      Get a string representation of the object for printing.\n",
            " |  \n",
            " |  async abatch(self, inputs: 'List[LanguageModelInput]', config: 'Optional[Union[RunnableConfig, List[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Any') -> 'List[str]'\n",
            " |      Default implementation runs ainvoke in parallel using asyncio.gather.\n",
            " |      \n",
            " |      The default implementation of batch works well for IO bound runnables.\n",
            " |      \n",
            " |      Subclasses should override this method if they can batch more efficiently;\n",
            " |      e.g., if the underlying Runnable uses an API which supports a batch mode.\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: A list of inputs to the Runnable.\n",
            " |          config: A config to use when invoking the Runnable.\n",
            " |             The config supports standard keys like 'tags', 'metadata' for tracing\n",
            " |             purposes, 'max_concurrency' for controlling how much work to do\n",
            " |             in parallel, and other keys. Please refer to the RunnableConfig\n",
            " |             for more details. Defaults to None.\n",
            " |          return_exceptions: Whether to return exceptions instead of raising them.\n",
            " |              Defaults to False.\n",
            " |          kwargs: Additional keyword arguments to pass to the Runnable.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A list of outputs from the Runnable.\n",
            " |  \n",
            " |  async agenerate(self, prompts: 'List[str]', stop: 'Optional[List[str]]' = None, callbacks: 'Optional[Union[Callbacks, List[Callbacks]]]' = None, *, tags: 'Optional[Union[List[str], List[List[str]]]]' = None, metadata: 'Optional[Union[Dict[str, Any], List[Dict[str, Any]]]]' = None, run_name: 'Optional[Union[str, List[str]]]' = None, run_id: 'Optional[Union[uuid.UUID, List[Optional[uuid.UUID]]]]' = None, **kwargs: 'Any') -> 'LLMResult'\n",
            " |      Asynchronously pass a sequence of prompts to a model and return generations.\n",
            " |      \n",
            " |      This method should make use of batched calls for models that expose a batched\n",
            " |      API.\n",
            " |      \n",
            " |      Use this method when you want to:\n",
            " |          1. take advantage of batched calls,\n",
            " |          2. need more output from the model than just the top generated value,\n",
            " |          3. are building chains that are agnostic to the underlying language model\n",
            " |              type (e.g., pure text completion models vs chat models).\n",
            " |      \n",
            " |      Args:\n",
            " |          prompts: List of string prompts.\n",
            " |          stop: Stop words to use when generating. Model output is cut off at the\n",
            " |              first occurrence of any of these substrings.\n",
            " |          callbacks: Callbacks to pass through. Used for executing additional\n",
            " |              functionality, such as logging or streaming, throughout generation.\n",
            " |          tags: List of tags to associate with each prompt. If provided, the length\n",
            " |              of the list must match the length of the prompts list.\n",
            " |          metadata: List of metadata dictionaries to associate with each prompt. If\n",
            " |              provided, the length of the list must match the length of the prompts\n",
            " |              list.\n",
            " |          run_name: List of run names to associate with each prompt. If provided, the\n",
            " |              length of the list must match the length of the prompts list.\n",
            " |          run_id: List of run IDs to associate with each prompt. If provided, the\n",
            " |              length of the list must match the length of the prompts list.\n",
            " |          **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
            " |              to the model provider API call.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An LLMResult, which contains a list of candidate Generations for each input\n",
            " |              prompt and additional model provider-specific output.\n",
            " |  \n",
            " |  async agenerate_prompt(self, prompts: 'List[PromptValue]', stop: 'Optional[List[str]]' = None, callbacks: 'Optional[Union[Callbacks, List[Callbacks]]]' = None, **kwargs: 'Any') -> 'LLMResult'\n",
            " |      Asynchronously pass a sequence of prompts and return model generations.\n",
            " |      \n",
            " |      This method should make use of batched calls for models that expose a batched\n",
            " |      API.\n",
            " |      \n",
            " |      Use this method when you want to:\n",
            " |          1. take advantage of batched calls,\n",
            " |          2. need more output from the model than just the top generated value,\n",
            " |          3. are building chains that are agnostic to the underlying language model\n",
            " |              type (e.g., pure text completion models vs chat models).\n",
            " |      \n",
            " |      Args:\n",
            " |          prompts: List of PromptValues. A PromptValue is an object that can be\n",
            " |              converted to match the format of any language model (string for pure\n",
            " |              text generation models and BaseMessages for chat models).\n",
            " |          stop: Stop words to use when generating. Model output is cut off at the\n",
            " |              first occurrence of any of these substrings.\n",
            " |          callbacks: Callbacks to pass through. Used for executing additional\n",
            " |              functionality, such as logging or streaming, throughout generation.\n",
            " |          **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
            " |              to the model provider API call.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An LLMResult, which contains a list of candidate Generations for each input\n",
            " |              prompt and additional model provider-specific output.\n",
            " |  \n",
            " |  async ainvoke(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'str'\n",
            " |      Default implementation of ainvoke, calls invoke from a thread.\n",
            " |      \n",
            " |      The default implementation allows usage of async code even if\n",
            " |      the Runnable did not implement a native async version of invoke.\n",
            " |      \n",
            " |      Subclasses should override this method if they can run asynchronously.\n",
            " |  \n",
            " |  async apredict(self, text: 'str', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'str'\n",
            " |      .. deprecated:: langchain-core==0.1.7 Use ``ainvoke`` instead.\n",
            " |  \n",
            " |  async apredict_messages(self, messages: 'List[BaseMessage]', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'BaseMessage'\n",
            " |      .. deprecated:: langchain-core==0.1.7 Use ``ainvoke`` instead.\n",
            " |  \n",
            " |  async astream(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'AsyncIterator[str]'\n",
            " |      Default implementation of astream, which calls ainvoke.\n",
            " |      Subclasses should override this method if they support streaming output.\n",
            " |      \n",
            " |      Args:\n",
            " |          input: The input to the Runnable.\n",
            " |          config: The config to use for the Runnable. Defaults to None.\n",
            " |          kwargs: Additional keyword arguments to pass to the Runnable.\n",
            " |      \n",
            " |      Yields:\n",
            " |          The output of the Runnable.\n",
            " |  \n",
            " |  batch(self, inputs: 'List[LanguageModelInput]', config: 'Optional[Union[RunnableConfig, List[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Any') -> 'List[str]'\n",
            " |      Default implementation runs invoke in parallel using a thread pool executor.\n",
            " |      \n",
            " |      The default implementation of batch works well for IO bound runnables.\n",
            " |      \n",
            " |      Subclasses should override this method if they can batch more efficiently;\n",
            " |      e.g., if the underlying Runnable uses an API which supports a batch mode.\n",
            " |  \n",
            " |  dict(self, **kwargs: 'Any') -> 'Dict'\n",
            " |      Return a dictionary of the LLM.\n",
            " |  \n",
            " |  generate(self, prompts: 'List[str]', stop: 'Optional[List[str]]' = None, callbacks: 'Optional[Union[Callbacks, List[Callbacks]]]' = None, *, tags: 'Optional[Union[List[str], List[List[str]]]]' = None, metadata: 'Optional[Union[Dict[str, Any], List[Dict[str, Any]]]]' = None, run_name: 'Optional[Union[str, List[str]]]' = None, run_id: 'Optional[Union[uuid.UUID, List[Optional[uuid.UUID]]]]' = None, **kwargs: 'Any') -> 'LLMResult'\n",
            " |      Pass a sequence of prompts to a model and return generations.\n",
            " |      \n",
            " |      This method should make use of batched calls for models that expose a batched\n",
            " |      API.\n",
            " |      \n",
            " |      Use this method when you want to:\n",
            " |          1. take advantage of batched calls,\n",
            " |          2. need more output from the model than just the top generated value,\n",
            " |          3. are building chains that are agnostic to the underlying language model\n",
            " |              type (e.g., pure text completion models vs chat models).\n",
            " |      \n",
            " |      Args:\n",
            " |          prompts: List of string prompts.\n",
            " |          stop: Stop words to use when generating. Model output is cut off at the\n",
            " |              first occurrence of any of these substrings.\n",
            " |          callbacks: Callbacks to pass through. Used for executing additional\n",
            " |              functionality, such as logging or streaming, throughout generation.\n",
            " |          tags: List of tags to associate with each prompt. If provided, the length\n",
            " |              of the list must match the length of the prompts list.\n",
            " |          metadata: List of metadata dictionaries to associate with each prompt. If\n",
            " |              provided, the length of the list must match the length of the prompts\n",
            " |              list.\n",
            " |          run_name: List of run names to associate with each prompt. If provided, the\n",
            " |              length of the list must match the length of the prompts list.\n",
            " |          run_id: List of run IDs to associate with each prompt. If provided, the\n",
            " |              length of the list must match the length of the prompts list.\n",
            " |          **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
            " |              to the model provider API call.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An LLMResult, which contains a list of candidate Generations for each input\n",
            " |              prompt and additional model provider-specific output.\n",
            " |  \n",
            " |  generate_prompt(self, prompts: 'List[PromptValue]', stop: 'Optional[List[str]]' = None, callbacks: 'Optional[Union[Callbacks, List[Callbacks]]]' = None, **kwargs: 'Any') -> 'LLMResult'\n",
            " |      Pass a sequence of prompts to the model and return model generations.\n",
            " |      \n",
            " |      This method should make use of batched calls for models that expose a batched\n",
            " |      API.\n",
            " |      \n",
            " |      Use this method when you want to:\n",
            " |          1. take advantage of batched calls,\n",
            " |          2. need more output from the model than just the top generated value,\n",
            " |          3. are building chains that are agnostic to the underlying language model\n",
            " |              type (e.g., pure text completion models vs chat models).\n",
            " |      \n",
            " |      Args:\n",
            " |          prompts: List of PromptValues. A PromptValue is an object that can be\n",
            " |              converted to match the format of any language model (string for pure\n",
            " |              text generation models and BaseMessages for chat models).\n",
            " |          stop: Stop words to use when generating. Model output is cut off at the\n",
            " |              first occurrence of any of these substrings.\n",
            " |          callbacks: Callbacks to pass through. Used for executing additional\n",
            " |              functionality, such as logging or streaming, throughout generation.\n",
            " |          **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
            " |              to the model provider API call.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An LLMResult, which contains a list of candidate Generations for each input\n",
            " |              prompt and additional model provider-specific output.\n",
            " |  \n",
            " |  invoke(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'str'\n",
            " |      Transform a single input into an output. Override to implement.\n",
            " |      \n",
            " |      Args:\n",
            " |          input: The input to the Runnable.\n",
            " |          config: A config to use when invoking the Runnable.\n",
            " |             The config supports standard keys like 'tags', 'metadata' for tracing\n",
            " |             purposes, 'max_concurrency' for controlling how much work to do\n",
            " |             in parallel, and other keys. Please refer to the RunnableConfig\n",
            " |             for more details.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The output of the Runnable.\n",
            " |  \n",
            " |  predict(self, text: 'str', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'str'\n",
            " |      .. deprecated:: langchain-core==0.1.7 Use ``invoke`` instead.\n",
            " |  \n",
            " |  predict_messages(self, messages: 'List[BaseMessage]', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'BaseMessage'\n",
            " |      .. deprecated:: langchain-core==0.1.7 Use ``invoke`` instead.\n",
            " |  \n",
            " |  save(self, file_path: 'Union[Path, str]') -> 'None'\n",
            " |      Save the LLM.\n",
            " |      \n",
            " |      Args:\n",
            " |          file_path: Path to file to save the LLM to.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: If the file path is not a string or Path object.\n",
            " |      \n",
            " |      Example:\n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          llm.save(file_path=\"path/llm.yaml\")\n",
            " |  \n",
            " |  stream(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'Iterator[str]'\n",
            " |      Default implementation of stream, which calls invoke.\n",
            " |      Subclasses should override this method if they support streaming output.\n",
            " |      \n",
            " |      Args:\n",
            " |          input: The input to the Runnable.\n",
            " |          config: The config to use for the Runnable. Defaults to None.\n",
            " |          kwargs: Additional keyword arguments to pass to the Runnable.\n",
            " |      \n",
            " |      Yields:\n",
            " |          The output of the Runnable.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from langchain_core.language_models.llms.BaseLLM:\n",
            " |  \n",
            " |  raise_deprecation(values: 'Dict') -> 'Dict' from pydantic.v1.main.ModelMetaclass\n",
            " |      Raise deprecation warning if callback_manager is used.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from langchain_core.language_models.llms.BaseLLM:\n",
            " |  \n",
            " |  OutputType\n",
            " |      Get the input type for this runnable.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from langchain_core.language_models.llms.BaseLLM:\n",
            " |  \n",
            " |  __orig_bases__ = (langchain_core.language_models.base.BaseLanguageMode...\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from langchain_core.language_models.base.BaseLanguageModel:\n",
            " |  \n",
            " |  get_num_tokens(self, text: 'str') -> 'int'\n",
            " |      Get the number of tokens present in the text.\n",
            " |      \n",
            " |      Useful for checking if an input fits in a model's context window.\n",
            " |      \n",
            " |      Args:\n",
            " |          text: The string input to tokenize.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The integer number of tokens in the text.\n",
            " |  \n",
            " |  get_num_tokens_from_messages(self, messages: 'List[BaseMessage]') -> 'int'\n",
            " |      Get the number of tokens in the messages.\n",
            " |      \n",
            " |      Useful for checking if an input fits in a model's context window.\n",
            " |      \n",
            " |      Args:\n",
            " |          messages: The message inputs to tokenize.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The sum of the number of tokens across the messages.\n",
            " |  \n",
            " |  get_token_ids(self, text: 'str') -> 'List[int]'\n",
            " |      Return the ordered ids of the tokens in a text.\n",
            " |      \n",
            " |      Args:\n",
            " |          text: The string input to tokenize.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A list of ids corresponding to the tokens in the text, in order they occur\n",
            " |              in the text.\n",
            " |  \n",
            " |  with_structured_output(self, schema: 'Union[Dict, Type[BaseModel]]', **kwargs: 'Any') -> 'Runnable[LanguageModelInput, Union[Dict, BaseModel]]'\n",
            " |      Not implemented on this class.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from langchain_core.language_models.base.BaseLanguageModel:\n",
            " |  \n",
            " |  set_verbose(verbose: 'Optional[bool]') -> 'bool' from pydantic.v1.main.ModelMetaclass\n",
            " |      If verbose is None, set it.\n",
            " |      \n",
            " |      This allows users to pass in None as verbose to access the global setting.\n",
            " |      \n",
            " |      Args:\n",
            " |          verbose: The verbosity setting to use.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The verbosity setting to use.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from langchain_core.language_models.base.BaseLanguageModel:\n",
            " |  \n",
            " |  InputType\n",
            " |      Get the input type for this runnable.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from langchain_core.runnables.base.RunnableSerializable:\n",
            " |  \n",
            " |  configurable_alternatives(self, which: 'ConfigurableField', *, default_key: 'str' = 'default', prefix_keys: 'bool' = False, **kwargs: 'Union[Runnable[Input, Output], Callable[[], Runnable[Input, Output]]]') -> 'RunnableSerializable[Input, Output]'\n",
            " |      Configure alternatives for Runnables that can be set at runtime.\n",
            " |      \n",
            " |      Args:\n",
            " |          which: The ConfigurableField instance that will be used to select the\n",
            " |              alternative.\n",
            " |          default_key: The default key to use if no alternative is selected.\n",
            " |              Defaults to \"default\".\n",
            " |          prefix_keys: Whether to prefix the keys with the ConfigurableField id.\n",
            " |              Defaults to False.\n",
            " |          **kwargs: A dictionary of keys to Runnable instances or callables that\n",
            " |              return Runnable instances.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new Runnable with the alternatives configured.\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from langchain_anthropic import ChatAnthropic\n",
            " |          from langchain_core.runnables.utils import ConfigurableField\n",
            " |          from langchain_openai import ChatOpenAI\n",
            " |      \n",
            " |          model = ChatAnthropic(\n",
            " |              model_name=\"claude-3-sonnet-20240229\"\n",
            " |          ).configurable_alternatives(\n",
            " |              ConfigurableField(id=\"llm\"),\n",
            " |              default_key=\"anthropic\",\n",
            " |              openai=ChatOpenAI()\n",
            " |          )\n",
            " |      \n",
            " |          # uses the default model ChatAnthropic\n",
            " |          print(model.invoke(\"which organization created you?\").content)\n",
            " |      \n",
            " |          # uses ChatOpenAI\n",
            " |          print(\n",
            " |              model.with_config(\n",
            " |                  configurable={\"llm\": \"openai\"}\n",
            " |              ).invoke(\"which organization created you?\").content\n",
            " |          )\n",
            " |  \n",
            " |  configurable_fields(self, **kwargs: 'AnyConfigurableField') -> 'RunnableSerializable[Input, Output]'\n",
            " |      Configure particular Runnable fields at runtime.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: A dictionary of ConfigurableField instances to configure.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new Runnable with the fields configured.\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from langchain_core.runnables import ConfigurableField\n",
            " |          from langchain_openai import ChatOpenAI\n",
            " |      \n",
            " |          model = ChatOpenAI(max_tokens=20).configurable_fields(\n",
            " |              max_tokens=ConfigurableField(\n",
            " |                  id=\"output_token_number\",\n",
            " |                  name=\"Max tokens in the output\",\n",
            " |                  description=\"The maximum number of tokens in the output\",\n",
            " |              )\n",
            " |          )\n",
            " |      \n",
            " |          # max_tokens = 20\n",
            " |          print(\n",
            " |              \"max_tokens_20: \",\n",
            " |              model.invoke(\"tell me something about chess\").content\n",
            " |          )\n",
            " |      \n",
            " |          # max_tokens = 200\n",
            " |          print(\"max_tokens_200: \", model.with_config(\n",
            " |              configurable={\"output_token_number\": 200}\n",
            " |              ).invoke(\"tell me something about chess\").content\n",
            " |          )\n",
            " |  \n",
            " |  to_json(self) -> 'Union[SerializedConstructor, SerializedNotImplemented]'\n",
            " |      Serialize the Runnable to JSON.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A JSON-serializable representation of the Runnable.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from langchain_core.runnables.base.RunnableSerializable:\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from langchain_core.load.serializable.Serializable:\n",
            " |  \n",
            " |  __init__(self, *args: Any, **kwargs: Any) -> None\n",
            " |      # Remove default BaseModel init docstring.\n",
            " |  \n",
            " |  __repr_args__(self) -> Any\n",
            " |      Returns the attributes to show in __str__, __repr__, and __pretty__ this is generally overridden.\n",
            " |      \n",
            " |      Can either return:\n",
            " |      * name - value pairs, e.g.: `[('foo_name', 'foo'), ('bar_name', ['b', 'a', 'r'])]`\n",
            " |      * or, just values, e.g.: `[(None, 'foo'), (None, ['b', 'a', 'r'])]`\n",
            " |  \n",
            " |  to_json_not_implemented(self) -> langchain_core.load.serializable.SerializedNotImplemented\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from langchain_core.load.serializable.Serializable:\n",
            " |  \n",
            " |  get_lc_namespace() -> List[str] from pydantic.v1.main.ModelMetaclass\n",
            " |      Get the namespace of the langchain object.\n",
            " |      \n",
            " |      For example, if the class is `langchain.llms.openai.OpenAI`, then the\n",
            " |      namespace is [\"langchain\", \"llms\", \"openai\"]\n",
            " |  \n",
            " |  is_lc_serializable() -> bool from pydantic.v1.main.ModelMetaclass\n",
            " |      Is this class serializable?\n",
            " |      \n",
            " |      By design, even if a class inherits from Serializable, it is not serializable by\n",
            " |      default. This is to prevent accidental serialization of objects that should not\n",
            " |      be serialized.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Whether the class is serializable. Default is False.\n",
            " |  \n",
            " |  lc_id() -> List[str] from pydantic.v1.main.ModelMetaclass\n",
            " |      A unique identifier for this class for serialization purposes.\n",
            " |      \n",
            " |      The unique identifier is a list of strings that describes the path\n",
            " |      to the object.\n",
            " |      For example, for the class `langchain.llms.openai.OpenAI`, the id is\n",
            " |      [\"langchain\", \"llms\", \"openai\", \"OpenAI\"].\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from langchain_core.load.serializable.Serializable:\n",
            " |  \n",
            " |  lc_attributes\n",
            " |      List of attribute names that should be included in the serialized kwargs.\n",
            " |      \n",
            " |      These attributes must be accepted by the constructor.\n",
            " |      Default is an empty dictionary.\n",
            " |  \n",
            " |  lc_secrets\n",
            " |      A map of constructor argument names to secret ids.\n",
            " |      \n",
            " |      For example,\n",
            " |          {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from pydantic.v1.main.BaseModel:\n",
            " |  \n",
            " |  __eq__(self, other: Any) -> bool\n",
            " |      Return self==value.\n",
            " |  \n",
            " |  __getstate__(self) -> 'DictAny'\n",
            " |  \n",
            " |  __iter__(self) -> 'TupleGenerator'\n",
            " |      so `dict(model)` works\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Implement setattr(self, name, value).\n",
            " |  \n",
            " |  __setstate__(self, state: 'DictAny') -> None\n",
            " |  \n",
            " |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
            " |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
            " |      \n",
            " |      :param include: fields to include in new model\n",
            " |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
            " |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
            " |          the new model: you should trust this data\n",
            " |      :param deep: set to `True` to make a deep copy of the model\n",
            " |      :return: new model instance\n",
            " |  \n",
            " |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> str\n",
            " |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
            " |      \n",
            " |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from pydantic.v1.main.BaseModel:\n",
            " |  \n",
            " |  __get_validators__() -> 'CallableGenerator' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
            " |      Same as update_forward_refs but will not raise exception\n",
            " |      when forward references are not defined.\n",
            " |  \n",
            " |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
            " |      Default values are respected, but no other validation is performed.\n",
            " |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
            " |  \n",
            " |  from_orm(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  parse_file(path: Union[str, pathlib.Path], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  parse_obj(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  parse_raw(b: Union[str, bytes], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  schema(by_alias: bool = True, ref_template: str = '#/definitions/{model}') -> 'DictStrAny' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  schema_json(*, by_alias: bool = True, ref_template: str = '#/definitions/{model}', **dumps_kwargs: Any) -> str from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  update_forward_refs(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
            " |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
            " |  \n",
            " |  validate(value: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from pydantic.v1.main.BaseModel:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __fields_set__\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from pydantic.v1.utils.Representation:\n",
            " |  \n",
            " |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
            " |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
            " |  \n",
            " |  __repr__(self) -> str\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __repr_name__(self) -> str\n",
            " |      Name of the instance's class, used in __repr__.\n",
            " |  \n",
            " |  __repr_str__(self, join_str: str) -> str\n",
            " |  \n",
            " |  __rich_repr__(self) -> 'RichReprResult'\n",
            " |      Get fields for Rich library\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from langchain_core.runnables.base.Runnable:\n",
            " |  \n",
            " |  __or__(self, other: 'Union[Runnable[Any, Other], Callable[[Any], Other], Callable[[Iterator[Any]], Iterator[Other]], Mapping[str, Union[Runnable[Any, Other], Callable[[Any], Other], Any]]]') -> 'RunnableSerializable[Input, Other]'\n",
            " |      Compose this Runnable with another object to create a RunnableSequence.\n",
            " |  \n",
            " |  __ror__(self, other: 'Union[Runnable[Other, Any], Callable[[Other], Any], Callable[[Iterator[Other]], Iterator[Any]], Mapping[str, Union[Runnable[Other, Any], Callable[[Other], Any], Any]]]') -> 'RunnableSerializable[Other, Output]'\n",
            " |      Compose this Runnable with another object to create a RunnableSequence.\n",
            " |  \n",
            " |  async abatch_as_completed(self, inputs: 'Sequence[Input]', config: 'Optional[Union[RunnableConfig, Sequence[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'AsyncIterator[Tuple[int, Union[Output, Exception]]]'\n",
            " |      Run ainvoke in parallel on a list of inputs,\n",
            " |      yielding results as they complete.\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: A list of inputs to the Runnable.\n",
            " |          config: A config to use when invoking the Runnable.\n",
            " |             The config supports standard keys like 'tags', 'metadata' for tracing\n",
            " |             purposes, 'max_concurrency' for controlling how much work to do\n",
            " |             in parallel, and other keys. Please refer to the RunnableConfig\n",
            " |             for more details. Defaults to None. Defaults to None.\n",
            " |          return_exceptions: Whether to return exceptions instead of raising them.\n",
            " |              Defaults to False.\n",
            " |          kwargs: Additional keyword arguments to pass to the Runnable.\n",
            " |      \n",
            " |      Yields:\n",
            " |          A tuple of the index of the input and the output from the Runnable.\n",
            " |  \n",
            " |  as_tool(self, args_schema: 'Optional[Type[BaseModel]]' = None, *, name: 'Optional[str]' = None, description: 'Optional[str]' = None, arg_types: 'Optional[Dict[str, Type]]' = None) -> 'BaseTool'\n",
            " |      .. beta::\n",
            " |         This API is in beta and may change in the future.\n",
            " |      \n",
            " |      Create a BaseTool from a Runnable.\n",
            " |      \n",
            " |      ``as_tool`` will instantiate a BaseTool with a name, description, and\n",
            " |      ``args_schema`` from a Runnable. Where possible, schemas are inferred\n",
            " |      from ``runnable.get_input_schema``. Alternatively (e.g., if the\n",
            " |      Runnable takes a dict as input and the specific dict keys are not typed),\n",
            " |      the schema can be specified directly with ``args_schema``. You can also\n",
            " |      pass ``arg_types`` to just specify the required arguments and their types.\n",
            " |      \n",
            " |      Args:\n",
            " |          args_schema: The schema for the tool. Defaults to None.\n",
            " |          name: The name of the tool. Defaults to None.\n",
            " |          description: The description of the tool. Defaults to None.\n",
            " |          arg_types: A dictionary of argument names to types. Defaults to None.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A BaseTool instance.\n",
            " |      \n",
            " |      Typed dict input:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from typing import List\n",
            " |          from typing_extensions import TypedDict\n",
            " |          from langchain_core.runnables import RunnableLambda\n",
            " |      \n",
            " |          class Args(TypedDict):\n",
            " |              a: int\n",
            " |              b: List[int]\n",
            " |      \n",
            " |          def f(x: Args) -> str:\n",
            " |              return str(x[\"a\"] * max(x[\"b\"]))\n",
            " |      \n",
            " |          runnable = RunnableLambda(f)\n",
            " |          as_tool = runnable.as_tool()\n",
            " |          as_tool.invoke({\"a\": 3, \"b\": [1, 2]})\n",
            " |      \n",
            " |      ``dict`` input, specifying schema via ``args_schema``:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from typing import Any, Dict, List\n",
            " |          from langchain_core.pydantic_v1 import BaseModel, Field\n",
            " |          from langchain_core.runnables import RunnableLambda\n",
            " |      \n",
            " |          def f(x: Dict[str, Any]) -> str:\n",
            " |              return str(x[\"a\"] * max(x[\"b\"]))\n",
            " |      \n",
            " |          class FSchema(BaseModel):\n",
            " |              \"\"\"Apply a function to an integer and list of integers.\"\"\"\n",
            " |      \n",
            " |              a: int = Field(..., description=\"Integer\")\n",
            " |              b: List[int] = Field(..., description=\"List of ints\")\n",
            " |      \n",
            " |          runnable = RunnableLambda(f)\n",
            " |          as_tool = runnable.as_tool(FSchema)\n",
            " |          as_tool.invoke({\"a\": 3, \"b\": [1, 2]})\n",
            " |      \n",
            " |      ``dict`` input, specifying schema via ``arg_types``:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from typing import Any, Dict, List\n",
            " |          from langchain_core.runnables import RunnableLambda\n",
            " |      \n",
            " |          def f(x: Dict[str, Any]) -> str:\n",
            " |              return str(x[\"a\"] * max(x[\"b\"]))\n",
            " |      \n",
            " |          runnable = RunnableLambda(f)\n",
            " |          as_tool = runnable.as_tool(arg_types={\"a\": int, \"b\": List[int]})\n",
            " |          as_tool.invoke({\"a\": 3, \"b\": [1, 2]})\n",
            " |      \n",
            " |      String input:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from langchain_core.runnables import RunnableLambda\n",
            " |      \n",
            " |          def f(x: str) -> str:\n",
            " |              return x + \"a\"\n",
            " |      \n",
            " |          def g(x: str) -> str:\n",
            " |              return x + \"z\"\n",
            " |      \n",
            " |          runnable = RunnableLambda(f) | g\n",
            " |          as_tool = runnable.as_tool()\n",
            " |          as_tool.invoke(\"b\")\n",
            " |      \n",
            " |      .. versionadded:: 0.2.14\n",
            " |  \n",
            " |  assign(self, **kwargs: 'Union[Runnable[Dict[str, Any], Any], Callable[[Dict[str, Any]], Any], Mapping[str, Union[Runnable[Dict[str, Any], Any], Callable[[Dict[str, Any]], Any]]]]') -> 'RunnableSerializable[Any, Any]'\n",
            " |      Assigns new fields to the dict output of this Runnable.\n",
            " |      Returns a new Runnable.\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from langchain_community.llms.fake import FakeStreamingListLLM\n",
            " |          from langchain_core.output_parsers import StrOutputParser\n",
            " |          from langchain_core.prompts import SystemMessagePromptTemplate\n",
            " |          from langchain_core.runnables import Runnable\n",
            " |          from operator import itemgetter\n",
            " |      \n",
            " |          prompt = (\n",
            " |              SystemMessagePromptTemplate.from_template(\"You are a nice assistant.\")\n",
            " |              + \"{question}\"\n",
            " |          )\n",
            " |          llm = FakeStreamingListLLM(responses=[\"foo-lish\"])\n",
            " |      \n",
            " |          chain: Runnable = prompt | llm | {\"str\": StrOutputParser()}\n",
            " |      \n",
            " |          chain_with_assign = chain.assign(hello=itemgetter(\"str\") | llm)\n",
            " |      \n",
            " |          print(chain_with_assign.input_schema.schema())\n",
            " |          # {'title': 'PromptInput', 'type': 'object', 'properties':\n",
            " |          {'question': {'title': 'Question', 'type': 'string'}}}\n",
            " |          print(chain_with_assign.output_schema.schema()) #\n",
            " |          {'title': 'RunnableSequenceOutput', 'type': 'object', 'properties':\n",
            " |          {'str': {'title': 'Str',\n",
            " |          'type': 'string'}, 'hello': {'title': 'Hello', 'type': 'string'}}}\n",
            " |  \n",
            " |  astream_events(self, input: 'Any', config: 'Optional[RunnableConfig]' = None, *, version: \"Literal['v1', 'v2']\", include_names: 'Optional[Sequence[str]]' = None, include_types: 'Optional[Sequence[str]]' = None, include_tags: 'Optional[Sequence[str]]' = None, exclude_names: 'Optional[Sequence[str]]' = None, exclude_types: 'Optional[Sequence[str]]' = None, exclude_tags: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'AsyncIterator[StreamEvent]'\n",
            " |      .. beta::\n",
            " |         This API is in beta and may change in the future.\n",
            " |      \n",
            " |      Generate a stream of events.\n",
            " |      \n",
            " |      Use to create an iterator over StreamEvents that provide real-time information\n",
            " |      about the progress of the Runnable, including StreamEvents from intermediate\n",
            " |      results.\n",
            " |      \n",
            " |      A StreamEvent is a dictionary with the following schema:\n",
            " |      \n",
            " |      - ``event``: **str** - Event names are of the\n",
            " |          format: on_[runnable_type]_(start|stream|end).\n",
            " |      - ``name``: **str** - The name of the Runnable that generated the event.\n",
            " |      - ``run_id``: **str** - randomly generated ID associated with the given execution of\n",
            " |          the Runnable that emitted the event.\n",
            " |          A child Runnable that gets invoked as part of the execution of a\n",
            " |          parent Runnable is assigned its own unique ID.\n",
            " |      - ``parent_ids``: **List[str]** - The IDs of the parent runnables that\n",
            " |          generated the event. The root Runnable will have an empty list.\n",
            " |          The order of the parent IDs is from the root to the immediate parent.\n",
            " |          Only available for v2 version of the API. The v1 version of the API\n",
            " |          will return an empty list.\n",
            " |      - ``tags``: **Optional[List[str]]** - The tags of the Runnable that generated\n",
            " |          the event.\n",
            " |      - ``metadata``: **Optional[Dict[str, Any]]** - The metadata of the Runnable\n",
            " |          that generated the event.\n",
            " |      - ``data``: **Dict[str, Any]**\n",
            " |      \n",
            " |      \n",
            " |      Below is a table that illustrates some evens that might be emitted by various\n",
            " |      chains. Metadata fields have been omitted from the table for brevity.\n",
            " |      Chain definitions have been included after the table.\n",
            " |      \n",
            " |      **ATTENTION** This reference table is for the V2 version of the schema.\n",
            " |      \n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | event                | name             | chunk                           | input                                         | output                                          |\n",
            " |      +======================+==================+=================================+===============================================+=================================================+\n",
            " |      | on_chat_model_start  | [model name]     |                                 | {\"messages\": [[SystemMessage, HumanMessage]]} |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_chat_model_stream | [model name]     | AIMessageChunk(content=\"hello\") |                                               |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_chat_model_end    | [model name]     |                                 | {\"messages\": [[SystemMessage, HumanMessage]]} | AIMessageChunk(content=\"hello world\")           |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_llm_start         | [model name]     |                                 | {'input': 'hello'}                            |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_llm_stream        | [model name]     | 'Hello'                         |                                               |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_llm_end           | [model name]     |                                 | 'Hello human!'                                |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_chain_start       | format_docs      |                                 |                                               |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_chain_stream      | format_docs      | \"hello world!, goodbye world!\"  |                                               |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_chain_end         | format_docs      |                                 | [Document(...)]                               | \"hello world!, goodbye world!\"                  |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_tool_start        | some_tool        |                                 | {\"x\": 1, \"y\": \"2\"}                            |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_tool_end          | some_tool        |                                 |                                               | {\"x\": 1, \"y\": \"2\"}                              |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_retriever_start   | [retriever name] |                                 | {\"query\": \"hello\"}                            |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_retriever_end     | [retriever name] |                                 | {\"query\": \"hello\"}                            | [Document(...), ..]                             |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_prompt_start      | [template_name]  |                                 | {\"question\": \"hello\"}                         |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_prompt_end        | [template_name]  |                                 | {\"question\": \"hello\"}                         | ChatPromptValue(messages: [SystemMessage, ...]) |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      \n",
            " |      In addition to the standard events, users can also dispatch custom events (see example below).\n",
            " |      \n",
            " |      Custom events will be only be surfaced with in the `v2` version of the API!\n",
            " |      \n",
            " |      A custom event has following format:\n",
            " |      \n",
            " |      +-----------+------+-----------------------------------------------------------------------------------------------------------+\n",
            " |      | Attribute | Type | Description                                                                                               |\n",
            " |      +===========+======+===========================================================================================================+\n",
            " |      | name      | str  | A user defined name for the event.                                                                        |\n",
            " |      +-----------+------+-----------------------------------------------------------------------------------------------------------+\n",
            " |      | data      | Any  | The data associated with the event. This can be anything, though we suggest making it JSON serializable.  |\n",
            " |      +-----------+------+-----------------------------------------------------------------------------------------------------------+\n",
            " |      \n",
            " |      Here are declarations associated with the standard events shown above:\n",
            " |      \n",
            " |      `format_docs`:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          def format_docs(docs: List[Document]) -> str:\n",
            " |              '''Format the docs.'''\n",
            " |              return \", \".join([doc.page_content for doc in docs])\n",
            " |      \n",
            " |          format_docs = RunnableLambda(format_docs)\n",
            " |      \n",
            " |      `some_tool`:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          @tool\n",
            " |          def some_tool(x: int, y: str) -> dict:\n",
            " |              '''Some_tool.'''\n",
            " |              return {\"x\": x, \"y\": y}\n",
            " |      \n",
            " |      `prompt`:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          template = ChatPromptTemplate.from_messages(\n",
            " |              [(\"system\", \"You are Cat Agent 007\"), (\"human\", \"{question}\")]\n",
            " |          ).with_config({\"run_name\": \"my_template\", \"tags\": [\"my_template\"]})\n",
            " |      \n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from langchain_core.runnables import RunnableLambda\n",
            " |      \n",
            " |          async def reverse(s: str) -> str:\n",
            " |              return s[::-1]\n",
            " |      \n",
            " |          chain = RunnableLambda(func=reverse)\n",
            " |      \n",
            " |          events = [\n",
            " |              event async for event in chain.astream_events(\"hello\", version=\"v2\")\n",
            " |          ]\n",
            " |      \n",
            " |          # will produce the following events (run_id, and parent_ids\n",
            " |          # has been omitted for brevity):\n",
            " |          [\n",
            " |              {\n",
            " |                  \"data\": {\"input\": \"hello\"},\n",
            " |                  \"event\": \"on_chain_start\",\n",
            " |                  \"metadata\": {},\n",
            " |                  \"name\": \"reverse\",\n",
            " |                  \"tags\": [],\n",
            " |              },\n",
            " |              {\n",
            " |                  \"data\": {\"chunk\": \"olleh\"},\n",
            " |                  \"event\": \"on_chain_stream\",\n",
            " |                  \"metadata\": {},\n",
            " |                  \"name\": \"reverse\",\n",
            " |                  \"tags\": [],\n",
            " |              },\n",
            " |              {\n",
            " |                  \"data\": {\"output\": \"olleh\"},\n",
            " |                  \"event\": \"on_chain_end\",\n",
            " |                  \"metadata\": {},\n",
            " |                  \"name\": \"reverse\",\n",
            " |                  \"tags\": [],\n",
            " |              },\n",
            " |          ]\n",
            " |      \n",
            " |      \n",
            " |      Example: Dispatch Custom Event\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from langchain_core.callbacks.manager import (\n",
            " |              adispatch_custom_event,\n",
            " |          )\n",
            " |          from langchain_core.runnables import RunnableLambda, RunnableConfig\n",
            " |          import asyncio\n",
            " |      \n",
            " |      \n",
            " |          async def slow_thing(some_input: str, config: RunnableConfig) -> str:\n",
            " |              \"\"\"Do something that takes a long time.\"\"\"\n",
            " |              await asyncio.sleep(1) # Placeholder for some slow operation\n",
            " |              await adispatch_custom_event(\n",
            " |                  \"progress_event\",\n",
            " |                  {\"message\": \"Finished step 1 of 3\"},\n",
            " |                  config=config # Must be included for python < 3.10\n",
            " |              )\n",
            " |              await asyncio.sleep(1) # Placeholder for some slow operation\n",
            " |              await adispatch_custom_event(\n",
            " |                  \"progress_event\",\n",
            " |                  {\"message\": \"Finished step 2 of 3\"},\n",
            " |                  config=config # Must be included for python < 3.10\n",
            " |              )\n",
            " |              await asyncio.sleep(1) # Placeholder for some slow operation\n",
            " |              return \"Done\"\n",
            " |      \n",
            " |          slow_thing = RunnableLambda(slow_thing)\n",
            " |      \n",
            " |          async for event in slow_thing.astream_events(\"some_input\", version=\"v2\"):\n",
            " |              print(event)\n",
            " |      \n",
            " |      Args:\n",
            " |          input: The input to the Runnable.\n",
            " |          config: The config to use for the Runnable.\n",
            " |          version: The version of the schema to use either `v2` or `v1`.\n",
            " |                   Users should use `v2`.\n",
            " |                   `v1` is for backwards compatibility and will be deprecated\n",
            " |                   in 0.4.0.\n",
            " |                   No default will be assigned until the API is stabilized.\n",
            " |                   custom events will only be surfaced in `v2`.\n",
            " |          include_names: Only include events from runnables with matching names.\n",
            " |          include_types: Only include events from runnables with matching types.\n",
            " |          include_tags: Only include events from runnables with matching tags.\n",
            " |          exclude_names: Exclude events from runnables with matching names.\n",
            " |          exclude_types: Exclude events from runnables with matching types.\n",
            " |          exclude_tags: Exclude events from runnables with matching tags.\n",
            " |          kwargs: Additional keyword arguments to pass to the Runnable.\n",
            " |              These will be passed to astream_log as this implementation\n",
            " |              of astream_events is built on top of astream_log.\n",
            " |      \n",
            " |      Yields:\n",
            " |          An async stream of StreamEvents.\n",
            " |      \n",
            " |      Raises:\n",
            " |          NotImplementedError: If the version is not `v1` or `v2`.\n",
            " |  \n",
            " |  async astream_log(self, input: 'Any', config: 'Optional[RunnableConfig]' = None, *, diff: 'bool' = True, with_streamed_output_list: 'bool' = True, include_names: 'Optional[Sequence[str]]' = None, include_types: 'Optional[Sequence[str]]' = None, include_tags: 'Optional[Sequence[str]]' = None, exclude_names: 'Optional[Sequence[str]]' = None, exclude_types: 'Optional[Sequence[str]]' = None, exclude_tags: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'Union[AsyncIterator[RunLogPatch], AsyncIterator[RunLog]]'\n",
            " |      Stream all output from a Runnable, as reported to the callback system.\n",
            " |      This includes all inner runs of LLMs, Retrievers, Tools, etc.\n",
            " |      \n",
            " |      Output is streamed as Log objects, which include a list of\n",
            " |      Jsonpatch ops that describe how the state of the run has changed in each\n",
            " |      step, and the final state of the run.\n",
            " |      \n",
            " |      The Jsonpatch ops can be applied in order to construct state.\n",
            " |      \n",
            " |      Args:\n",
            " |          input: The input to the Runnable.\n",
            " |          config: The config to use for the Runnable.\n",
            " |          diff: Whether to yield diffs between each step or the current state.\n",
            " |          with_streamed_output_list: Whether to yield the streamed_output list.\n",
            " |          include_names: Only include logs with these names.\n",
            " |          include_types: Only include logs with these types.\n",
            " |          include_tags: Only include logs with these tags.\n",
            " |          exclude_names: Exclude logs with these names.\n",
            " |          exclude_types: Exclude logs with these types.\n",
            " |          exclude_tags: Exclude logs with these tags.\n",
            " |          kwargs: Additional keyword arguments to pass to the Runnable.\n",
            " |      \n",
            " |      Yields:\n",
            " |          A RunLogPatch or RunLog object.\n",
            " |  \n",
            " |  async atransform(self, input: 'AsyncIterator[Input]', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'AsyncIterator[Output]'\n",
            " |      Default implementation of atransform, which buffers input and calls astream.\n",
            " |      Subclasses should override this method if they can start producing output while\n",
            " |      input is still being generated.\n",
            " |      \n",
            " |      Args:\n",
            " |          input: An async iterator of inputs to the Runnable.\n",
            " |          config: The config to use for the Runnable. Defaults to None.\n",
            " |          kwargs: Additional keyword arguments to pass to the Runnable.\n",
            " |      \n",
            " |      Yields:\n",
            " |          The output of the Runnable.\n",
            " |  \n",
            " |  batch_as_completed(self, inputs: 'Sequence[Input]', config: 'Optional[Union[RunnableConfig, Sequence[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'Iterator[Tuple[int, Union[Output, Exception]]]'\n",
            " |      Run invoke in parallel on a list of inputs,\n",
            " |      yielding results as they complete.\n",
            " |  \n",
            " |  bind(self, **kwargs: 'Any') -> 'Runnable[Input, Output]'\n",
            " |      Bind arguments to a Runnable, returning a new Runnable.\n",
            " |      \n",
            " |      Useful when a Runnable in a chain requires an argument that is not\n",
            " |      in the output of the previous Runnable or included in the user input.\n",
            " |      \n",
            " |      Args:\n",
            " |          kwargs: The arguments to bind to the Runnable.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new Runnable with the arguments bound.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from langchain_community.chat_models import ChatOllama\n",
            " |          from langchain_core.output_parsers import StrOutputParser\n",
            " |      \n",
            " |          llm = ChatOllama(model='llama2')\n",
            " |      \n",
            " |          # Without bind.\n",
            " |          chain = (\n",
            " |              llm\n",
            " |              | StrOutputParser()\n",
            " |          )\n",
            " |      \n",
            " |          chain.invoke(\"Repeat quoted words exactly: 'One two three four five.'\")\n",
            " |          # Output is 'One two three four five.'\n",
            " |      \n",
            " |          # With bind.\n",
            " |          chain = (\n",
            " |              llm.bind(stop=[\"three\"])\n",
            " |              | StrOutputParser()\n",
            " |          )\n",
            " |      \n",
            " |          chain.invoke(\"Repeat quoted words exactly: 'One two three four five.'\")\n",
            " |          # Output is 'One two'\n",
            " |  \n",
            " |  config_schema(self, *, include: 'Optional[Sequence[str]]' = None) -> 'Type[BaseModel]'\n",
            " |      The type of config this Runnable accepts specified as a pydantic model.\n",
            " |      \n",
            " |      To mark a field as configurable, see the `configurable_fields`\n",
            " |      and `configurable_alternatives` methods.\n",
            " |      \n",
            " |      Args:\n",
            " |          include: A list of fields to include in the config schema.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A pydantic model that can be used to validate config.\n",
            " |  \n",
            " |  get_graph(self, config: 'Optional[RunnableConfig]' = None) -> 'Graph'\n",
            " |      Return a graph representation of this Runnable.\n",
            " |  \n",
            " |  get_input_schema(self, config: 'Optional[RunnableConfig]' = None) -> 'Type[BaseModel]'\n",
            " |      Get a pydantic model that can be used to validate input to the Runnable.\n",
            " |      \n",
            " |      Runnables that leverage the configurable_fields and configurable_alternatives\n",
            " |      methods will have a dynamic input schema that depends on which\n",
            " |      configuration the Runnable is invoked with.\n",
            " |      \n",
            " |      This method allows to get an input schema for a specific configuration.\n",
            " |      \n",
            " |      Args:\n",
            " |          config: A config to use when generating the schema.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A pydantic model that can be used to validate input.\n",
            " |  \n",
            " |  get_name(self, suffix: 'Optional[str]' = None, *, name: 'Optional[str]' = None) -> 'str'\n",
            " |      Get the name of the Runnable.\n",
            " |  \n",
            " |  get_output_schema(self, config: 'Optional[RunnableConfig]' = None) -> 'Type[BaseModel]'\n",
            " |      Get a pydantic model that can be used to validate output to the Runnable.\n",
            " |      \n",
            " |      Runnables that leverage the configurable_fields and configurable_alternatives\n",
            " |      methods will have a dynamic output schema that depends on which\n",
            " |      configuration the Runnable is invoked with.\n",
            " |      \n",
            " |      This method allows to get an output schema for a specific configuration.\n",
            " |      \n",
            " |      Args:\n",
            " |          config: A config to use when generating the schema.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A pydantic model that can be used to validate output.\n",
            " |  \n",
            " |  get_prompts(self, config: 'Optional[RunnableConfig]' = None) -> 'List[BasePromptTemplate]'\n",
            " |      Return a list of prompts used by this Runnable.\n",
            " |  \n",
            " |  map(self) -> 'Runnable[List[Input], List[Output]]'\n",
            " |      Return a new Runnable that maps a list of inputs to a list of outputs,\n",
            " |      by calling invoke() with each input.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new Runnable that maps a list of inputs to a list of outputs.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |          .. code-block:: python\n",
            " |      \n",
            " |                  from langchain_core.runnables import RunnableLambda\n",
            " |      \n",
            " |                  def _lambda(x: int) -> int:\n",
            " |                      return x + 1\n",
            " |      \n",
            " |                  runnable = RunnableLambda(_lambda)\n",
            " |                  print(runnable.map().invoke([1, 2, 3])) # [2, 3, 4]\n",
            " |  \n",
            " |  pick(self, keys: 'Union[str, List[str]]') -> 'RunnableSerializable[Any, Any]'\n",
            " |      Pick keys from the dict output of this Runnable.\n",
            " |      \n",
            " |      Pick single key:\n",
            " |          .. code-block:: python\n",
            " |      \n",
            " |              import json\n",
            " |      \n",
            " |              from langchain_core.runnables import RunnableLambda, RunnableMap\n",
            " |      \n",
            " |              as_str = RunnableLambda(str)\n",
            " |              as_json = RunnableLambda(json.loads)\n",
            " |              chain = RunnableMap(str=as_str, json=as_json)\n",
            " |      \n",
            " |              chain.invoke(\"[1, 2, 3]\")\n",
            " |              # -> {\"str\": \"[1, 2, 3]\", \"json\": [1, 2, 3]}\n",
            " |      \n",
            " |              json_only_chain = chain.pick(\"json\")\n",
            " |              json_only_chain.invoke(\"[1, 2, 3]\")\n",
            " |              # -> [1, 2, 3]\n",
            " |      \n",
            " |      Pick list of keys:\n",
            " |          .. code-block:: python\n",
            " |      \n",
            " |              from typing import Any\n",
            " |      \n",
            " |              import json\n",
            " |      \n",
            " |              from langchain_core.runnables import RunnableLambda, RunnableMap\n",
            " |      \n",
            " |              as_str = RunnableLambda(str)\n",
            " |              as_json = RunnableLambda(json.loads)\n",
            " |              def as_bytes(x: Any) -> bytes:\n",
            " |                  return bytes(x, \"utf-8\")\n",
            " |      \n",
            " |              chain = RunnableMap(\n",
            " |                  str=as_str,\n",
            " |                  json=as_json,\n",
            " |                  bytes=RunnableLambda(as_bytes)\n",
            " |              )\n",
            " |      \n",
            " |              chain.invoke(\"[1, 2, 3]\")\n",
            " |              # -> {\"str\": \"[1, 2, 3]\", \"json\": [1, 2, 3], \"bytes\": b\"[1, 2, 3]\"}\n",
            " |      \n",
            " |              json_and_bytes_chain = chain.pick([\"json\", \"bytes\"])\n",
            " |              json_and_bytes_chain.invoke(\"[1, 2, 3]\")\n",
            " |              # -> {\"json\": [1, 2, 3], \"bytes\": b\"[1, 2, 3]\"}\n",
            " |  \n",
            " |  pipe(self, *others: 'Union[Runnable[Any, Other], Callable[[Any], Other]]', name: 'Optional[str]' = None) -> 'RunnableSerializable[Input, Other]'\n",
            " |      Compose this Runnable with Runnable-like objects to make a RunnableSequence.\n",
            " |      \n",
            " |      Equivalent to `RunnableSequence(self, *others)` or `self | others[0] | ...`\n",
            " |      \n",
            " |      Example:\n",
            " |          .. code-block:: python\n",
            " |      \n",
            " |              from langchain_core.runnables import RunnableLambda\n",
            " |      \n",
            " |              def add_one(x: int) -> int:\n",
            " |                  return x + 1\n",
            " |      \n",
            " |              def mul_two(x: int) -> int:\n",
            " |                  return x * 2\n",
            " |      \n",
            " |              runnable_1 = RunnableLambda(add_one)\n",
            " |              runnable_2 = RunnableLambda(mul_two)\n",
            " |              sequence = runnable_1.pipe(runnable_2)\n",
            " |              # Or equivalently:\n",
            " |              # sequence = runnable_1 | runnable_2\n",
            " |              # sequence = RunnableSequence(first=runnable_1, last=runnable_2)\n",
            " |              sequence.invoke(1)\n",
            " |              await sequence.ainvoke(1)\n",
            " |              # -> 4\n",
            " |      \n",
            " |              sequence.batch([1, 2, 3])\n",
            " |              await sequence.abatch([1, 2, 3])\n",
            " |              # -> [4, 6, 8]\n",
            " |  \n",
            " |  transform(self, input: 'Iterator[Input]', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'Iterator[Output]'\n",
            " |      Default implementation of transform, which buffers input and then calls stream.\n",
            " |      Subclasses should override this method if they can start producing output while\n",
            " |      input is still being generated.\n",
            " |      \n",
            " |      Args:\n",
            " |          input: An iterator of inputs to the Runnable.\n",
            " |          config: The config to use for the Runnable. Defaults to None.\n",
            " |          kwargs: Additional keyword arguments to pass to the Runnable.\n",
            " |      \n",
            " |      Yields:\n",
            " |          The output of the Runnable.\n",
            " |  \n",
            " |  with_alisteners(self, *, on_start: 'Optional[AsyncListener]' = None, on_end: 'Optional[AsyncListener]' = None, on_error: 'Optional[AsyncListener]' = None) -> 'Runnable[Input, Output]'\n",
            " |      Bind asynchronous lifecycle listeners to a Runnable, returning a new Runnable.\n",
            " |      \n",
            " |      on_start: Asynchronously called before the Runnable starts running.\n",
            " |      on_end: Asynchronously called after the Runnable finishes running.\n",
            " |      on_error: Asynchronously called if the Runnable throws an error.\n",
            " |      \n",
            " |      The Run object contains information about the run, including its id,\n",
            " |      type, input, output, error, start_time, end_time, and any tags or metadata\n",
            " |      added to the run.\n",
            " |      \n",
            " |      Args:\n",
            " |          on_start: Asynchronously called before the Runnable starts running.\n",
            " |              Defaults to None.\n",
            " |          on_end: Asynchronously called after the Runnable finishes running.\n",
            " |              Defaults to None.\n",
            " |          on_error: Asynchronously called if the Runnable throws an error.\n",
            " |              Defaults to None.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new Runnable with the listeners bound.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from langchain_core.runnables import RunnableLambda\n",
            " |          import time\n",
            " |      \n",
            " |          async def test_runnable(time_to_sleep : int):\n",
            " |              print(f\"Runnable[{time_to_sleep}s]: starts at {format_t(time.time())}\")\n",
            " |              await asyncio.sleep(time_to_sleep)\n",
            " |              print(f\"Runnable[{time_to_sleep}s]: ends at {format_t(time.time())}\")\n",
            " |      \n",
            " |          async def fn_start(run_obj : Runnable):\n",
            " |              print(f\"on start callback starts at {format_t(time.time())}\n",
            " |              await asyncio.sleep(3)\n",
            " |              print(f\"on start callback ends at {format_t(time.time())}\")\n",
            " |      \n",
            " |          async def fn_end(run_obj : Runnable):\n",
            " |              print(f\"on end callback starts at {format_t(time.time())}\n",
            " |              await asyncio.sleep(2)\n",
            " |              print(f\"on end callback ends at {format_t(time.time())}\")\n",
            " |      \n",
            " |          runnable = RunnableLambda(test_runnable).with_alisteners(\n",
            " |              on_start=fn_start,\n",
            " |              on_end=fn_end\n",
            " |          )\n",
            " |          async def concurrent_runs():\n",
            " |              await asyncio.gather(runnable.ainvoke(2), runnable.ainvoke(3))\n",
            " |      \n",
            " |          asyncio.run(concurrent_runs())\n",
            " |          Result:\n",
            " |          on start callback starts at 2024-05-16T14:20:29.637053+00:00\n",
            " |          on start callback starts at 2024-05-16T14:20:29.637150+00:00\n",
            " |          on start callback ends at 2024-05-16T14:20:32.638305+00:00\n",
            " |          on start callback ends at 2024-05-16T14:20:32.638383+00:00\n",
            " |          Runnable[3s]: starts at 2024-05-16T14:20:32.638849+00:00\n",
            " |          Runnable[5s]: starts at 2024-05-16T14:20:32.638999+00:00\n",
            " |          Runnable[3s]: ends at 2024-05-16T14:20:35.640016+00:00\n",
            " |          on end callback starts at 2024-05-16T14:20:35.640534+00:00\n",
            " |          Runnable[5s]: ends at 2024-05-16T14:20:37.640169+00:00\n",
            " |          on end callback starts at 2024-05-16T14:20:37.640574+00:00\n",
            " |          on end callback ends at 2024-05-16T14:20:37.640654+00:00\n",
            " |          on end callback ends at 2024-05-16T14:20:39.641751+00:00\n",
            " |  \n",
            " |  with_config(self, config: 'Optional[RunnableConfig]' = None, **kwargs: 'Any') -> 'Runnable[Input, Output]'\n",
            " |      Bind config to a Runnable, returning a new Runnable.\n",
            " |      \n",
            " |      Args:\n",
            " |          config: The config to bind to the Runnable.\n",
            " |          kwargs: Additional keyword arguments to pass to the Runnable.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new Runnable with the config bound.\n",
            " |  \n",
            " |  with_fallbacks(self, fallbacks: 'Sequence[Runnable[Input, Output]]', *, exceptions_to_handle: 'Tuple[Type[BaseException], ...]' = (<class 'Exception'>,), exception_key: 'Optional[str]' = None) -> 'RunnableWithFallbacksT[Input, Output]'\n",
            " |      Add fallbacks to a Runnable, returning a new Runnable.\n",
            " |      \n",
            " |      The new Runnable will try the original Runnable, and then each fallback\n",
            " |      in order, upon failures.\n",
            " |      \n",
            " |      Args:\n",
            " |          fallbacks: A sequence of runnables to try if the original Runnable fails.\n",
            " |          exceptions_to_handle: A tuple of exception types to handle.\n",
            " |              Defaults to (Exception,).\n",
            " |          exception_key: If string is specified then handled exceptions will be passed\n",
            " |              to fallbacks as part of the input under the specified key. If None,\n",
            " |              exceptions will not be passed to fallbacks. If used, the base Runnable\n",
            " |              and its fallbacks must accept a dictionary as input. Defaults to None.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new Runnable that will try the original Runnable, and then each\n",
            " |          fallback in order, upon failures.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |          .. code-block:: python\n",
            " |      \n",
            " |              from typing import Iterator\n",
            " |      \n",
            " |              from langchain_core.runnables import RunnableGenerator\n",
            " |      \n",
            " |      \n",
            " |              def _generate_immediate_error(input: Iterator) -> Iterator[str]:\n",
            " |                  raise ValueError()\n",
            " |                  yield \"\"\n",
            " |      \n",
            " |      \n",
            " |              def _generate(input: Iterator) -> Iterator[str]:\n",
            " |                  yield from \"foo bar\"\n",
            " |      \n",
            " |      \n",
            " |              runnable = RunnableGenerator(_generate_immediate_error).with_fallbacks(\n",
            " |                  [RunnableGenerator(_generate)]\n",
            " |                  )\n",
            " |              print(''.join(runnable.stream({}))) #foo bar\n",
            " |      \n",
            " |      Args:\n",
            " |          fallbacks: A sequence of runnables to try if the original Runnable fails.\n",
            " |          exceptions_to_handle: A tuple of exception types to handle.\n",
            " |          exception_key: If string is specified then handled exceptions will be passed\n",
            " |              to fallbacks as part of the input under the specified key. If None,\n",
            " |              exceptions will not be passed to fallbacks. If used, the base Runnable\n",
            " |              and its fallbacks must accept a dictionary as input.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new Runnable that will try the original Runnable, and then each\n",
            " |          fallback in order, upon failures.\n",
            " |  \n",
            " |  with_listeners(self, *, on_start: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None, on_end: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None, on_error: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None) -> 'Runnable[Input, Output]'\n",
            " |      Bind lifecycle listeners to a Runnable, returning a new Runnable.\n",
            " |      \n",
            " |      on_start: Called before the Runnable starts running, with the Run object.\n",
            " |      on_end: Called after the Runnable finishes running, with the Run object.\n",
            " |      on_error: Called if the Runnable throws an error, with the Run object.\n",
            " |      \n",
            " |      The Run object contains information about the run, including its id,\n",
            " |      type, input, output, error, start_time, end_time, and any tags or metadata\n",
            " |      added to the run.\n",
            " |      \n",
            " |      Args:\n",
            " |          on_start: Called before the Runnable starts running. Defaults to None.\n",
            " |          on_end: Called after the Runnable finishes running. Defaults to None.\n",
            " |          on_error: Called if the Runnable throws an error. Defaults to None.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new Runnable with the listeners bound.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from langchain_core.runnables import RunnableLambda\n",
            " |          from langchain_core.tracers.schemas import Run\n",
            " |      \n",
            " |          import time\n",
            " |      \n",
            " |          def test_runnable(time_to_sleep : int):\n",
            " |              time.sleep(time_to_sleep)\n",
            " |      \n",
            " |          def fn_start(run_obj: Run):\n",
            " |              print(\"start_time:\", run_obj.start_time)\n",
            " |      \n",
            " |          def fn_end(run_obj: Run):\n",
            " |              print(\"end_time:\", run_obj.end_time)\n",
            " |      \n",
            " |          chain = RunnableLambda(test_runnable).with_listeners(\n",
            " |              on_start=fn_start,\n",
            " |              on_end=fn_end\n",
            " |          )\n",
            " |          chain.invoke(2)\n",
            " |  \n",
            " |  with_retry(self, *, retry_if_exception_type: 'Tuple[Type[BaseException], ...]' = (<class 'Exception'>,), wait_exponential_jitter: 'bool' = True, stop_after_attempt: 'int' = 3) -> 'Runnable[Input, Output]'\n",
            " |      Create a new Runnable that retries the original Runnable on exceptions.\n",
            " |      \n",
            " |      Args:\n",
            " |          retry_if_exception_type: A tuple of exception types to retry on.\n",
            " |              Defaults to (Exception,).\n",
            " |          wait_exponential_jitter: Whether to add jitter to the wait\n",
            " |              time between retries. Defaults to True.\n",
            " |          stop_after_attempt: The maximum number of attempts to make before\n",
            " |              giving up. Defaults to 3.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new Runnable that retries the original Runnable on exceptions.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          from langchain_core.runnables import RunnableLambda\n",
            " |      \n",
            " |          count = 0\n",
            " |      \n",
            " |      \n",
            " |          def _lambda(x: int) -> None:\n",
            " |              global count\n",
            " |              count = count + 1\n",
            " |              if x == 1:\n",
            " |                  raise ValueError(\"x is 1\")\n",
            " |              else:\n",
            " |                   pass\n",
            " |      \n",
            " |      \n",
            " |          runnable = RunnableLambda(_lambda)\n",
            " |          try:\n",
            " |              runnable.with_retry(\n",
            " |                  stop_after_attempt=2,\n",
            " |                  retry_if_exception_type=(ValueError,),\n",
            " |              ).invoke(1)\n",
            " |          except ValueError:\n",
            " |              pass\n",
            " |      \n",
            " |          assert (count == 2)\n",
            " |      \n",
            " |      \n",
            " |      Args:\n",
            " |          retry_if_exception_type: A tuple of exception types to retry on\n",
            " |          wait_exponential_jitter: Whether to add jitter to the wait time\n",
            " |                                   between retries\n",
            " |          stop_after_attempt: The maximum number of attempts to make before giving up\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new Runnable that retries the original Runnable on exceptions.\n",
            " |  \n",
            " |  with_types(self, *, input_type: 'Optional[Type[Input]]' = None, output_type: 'Optional[Type[Output]]' = None) -> 'Runnable[Input, Output]'\n",
            " |      Bind input and output types to a Runnable, returning a new Runnable.\n",
            " |      \n",
            " |      Args:\n",
            " |          input_type: The input type to bind to the Runnable. Defaults to None.\n",
            " |          output_type: The output type to bind to the Runnable. Defaults to None.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new Runnable with the types bound.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from langchain_core.runnables.base.Runnable:\n",
            " |  \n",
            " |  config_specs\n",
            " |      List configurable fields for this Runnable.\n",
            " |  \n",
            " |  input_schema\n",
            " |      The type of input this Runnable accepts specified as a pydantic model.\n",
            " |  \n",
            " |  output_schema\n",
            " |      The type of output this Runnable produces specified as a pydantic model.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from langchain_core.runnables.base.Runnable:\n",
            " |  \n",
            " |  name = None\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from typing.Generic:\n",
            " |  \n",
            " |  __class_getitem__(params) from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  __init_subclass__(*args, **kwargs) from pydantic.v1.main.ModelMetaclass\n",
            " |      This method is called when a class is subclassed.\n",
            " |      \n",
            " |      The default implementation does nothing. It may be\n",
            " |      overridden to extend subclasses.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(HuggingFaceEmbeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hFKAHy8Aity",
        "outputId": "e498eb34-6f2b-437e-d5da-160d2ec0912c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class HuggingFaceEmbeddings in module langchain_huggingface.embeddings.huggingface:\n",
            "\n",
            "class HuggingFaceEmbeddings(pydantic.v1.main.BaseModel, langchain_core.embeddings.embeddings.Embeddings)\n",
            " |  HuggingFaceEmbeddings(*, client: Any = None, model_name: str = 'sentence-transformers/all-mpnet-base-v2', cache_folder: Optional[str] = None, model_kwargs: Dict[str, Any] = None, encode_kwargs: Dict[str, Any] = None, multi_process: bool = False, show_progress: bool = False) -> None\n",
            " |  \n",
            " |  HuggingFace sentence_transformers embedding models.\n",
            " |  \n",
            " |  To use, you should have the ``sentence_transformers`` python package installed.\n",
            " |  \n",
            " |  Example:\n",
            " |      .. code-block:: python\n",
            " |  \n",
            " |          from langchain_huggingface import HuggingFaceEmbeddings\n",
            " |  \n",
            " |          model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
            " |          model_kwargs = {'device': 'cpu'}\n",
            " |          encode_kwargs = {'normalize_embeddings': False}\n",
            " |          hf = HuggingFaceEmbeddings(\n",
            " |              model_name=model_name,\n",
            " |              model_kwargs=model_kwargs,\n",
            " |              encode_kwargs=encode_kwargs\n",
            " |          )\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      HuggingFaceEmbeddings\n",
            " |      pydantic.v1.main.BaseModel\n",
            " |      pydantic.v1.utils.Representation\n",
            " |      langchain_core.embeddings.embeddings.Embeddings\n",
            " |      abc.ABC\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, **kwargs: Any)\n",
            " |      Initialize the sentence_transformer.\n",
            " |  \n",
            " |  embed_documents(self, texts: List[str]) -> List[List[float]]\n",
            " |      Compute doc embeddings using a HuggingFace transformer model.\n",
            " |      \n",
            " |      Args:\n",
            " |          texts: The list of texts to embed.\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of embeddings, one for each text.\n",
            " |  \n",
            " |  embed_query(self, text: str) -> List[float]\n",
            " |      Compute query embeddings using a HuggingFace transformer model.\n",
            " |      \n",
            " |      Args:\n",
            " |          text: The text to embed.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Embeddings for the text.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  Config = <class 'langchain_huggingface.embeddings.huggingface.HuggingF...\n",
            " |      Configuration for this pydantic object.\n",
            " |  \n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  __annotations__ = {'cache_folder': typing.Optional[str], 'client': typ...\n",
            " |  \n",
            " |  __class_vars__ = set()\n",
            " |  \n",
            " |  __config__ = <class 'pydantic.v1.config.Config'>\n",
            " |  \n",
            " |  __custom_root_type__ = False\n",
            " |  \n",
            " |  __exclude_fields__ = None\n",
            " |  \n",
            " |  __fields__ = {'cache_folder': ModelField(name='cache_folder', type=Opt...\n",
            " |  \n",
            " |  __hash__ = None\n",
            " |  \n",
            " |  __include_fields__ = None\n",
            " |  \n",
            " |  __post_root_validators__ = []\n",
            " |  \n",
            " |  __pre_root_validators__ = []\n",
            " |  \n",
            " |  __private_attributes__ = {}\n",
            " |  \n",
            " |  __schema_cache__ = {}\n",
            " |  \n",
            " |  __signature__ = <Signature (*, client: Any = None, model_name: s...ol ...\n",
            " |  \n",
            " |  __validators__ = {}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from pydantic.v1.main.BaseModel:\n",
            " |  \n",
            " |  __eq__(self, other: Any) -> bool\n",
            " |      Return self==value.\n",
            " |  \n",
            " |  __getstate__(self) -> 'DictAny'\n",
            " |  \n",
            " |  __iter__(self) -> 'TupleGenerator'\n",
            " |      so `dict(model)` works\n",
            " |  \n",
            " |  __repr_args__(self) -> 'ReprArgs'\n",
            " |      Returns the attributes to show in __str__, __repr__, and __pretty__ this is generally overridden.\n",
            " |      \n",
            " |      Can either return:\n",
            " |      * name - value pairs, e.g.: `[('foo_name', 'foo'), ('bar_name', ['b', 'a', 'r'])]`\n",
            " |      * or, just values, e.g.: `[(None, 'foo'), (None, ['b', 'a', 'r'])]`\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Implement setattr(self, name, value).\n",
            " |  \n",
            " |  __setstate__(self, state: 'DictAny') -> None\n",
            " |  \n",
            " |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
            " |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
            " |      \n",
            " |      :param include: fields to include in new model\n",
            " |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
            " |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
            " |          the new model: you should trust this data\n",
            " |      :param deep: set to `True` to make a deep copy of the model\n",
            " |      :return: new model instance\n",
            " |  \n",
            " |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
            " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
            " |  \n",
            " |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> str\n",
            " |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
            " |      \n",
            " |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from pydantic.v1.main.BaseModel:\n",
            " |  \n",
            " |  __get_validators__() -> 'CallableGenerator' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
            " |      Same as update_forward_refs but will not raise exception\n",
            " |      when forward references are not defined.\n",
            " |  \n",
            " |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
            " |      Default values are respected, but no other validation is performed.\n",
            " |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
            " |  \n",
            " |  from_orm(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  parse_file(path: Union[str, pathlib.Path], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  parse_obj(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  parse_raw(b: Union[str, bytes], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  schema(by_alias: bool = True, ref_template: str = '#/definitions/{model}') -> 'DictStrAny' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  schema_json(*, by_alias: bool = True, ref_template: str = '#/definitions/{model}', **dumps_kwargs: Any) -> str from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  update_forward_refs(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
            " |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
            " |  \n",
            " |  validate(value: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from pydantic.v1.main.BaseModel:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __fields_set__\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from pydantic.v1.utils.Representation:\n",
            " |  \n",
            " |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
            " |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
            " |  \n",
            " |  __repr__(self) -> str\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __repr_name__(self) -> str\n",
            " |      Name of the instance's class, used in __repr__.\n",
            " |  \n",
            " |  __repr_str__(self, join_str: str) -> str\n",
            " |  \n",
            " |  __rich_repr__(self) -> 'RichReprResult'\n",
            " |      Get fields for Rich library\n",
            " |  \n",
            " |  __str__(self) -> str\n",
            " |      Return str(self).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from langchain_core.embeddings.embeddings.Embeddings:\n",
            " |  \n",
            " |  async aembed_documents(self, texts: List[str]) -> List[List[float]]\n",
            " |      Asynchronous Embed search docs.\n",
            " |      \n",
            " |      Args:\n",
            " |          texts: List of text to embed.\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of embeddings.\n",
            " |  \n",
            " |  async aembed_query(self, text: str) -> List[float]\n",
            " |      Asynchronous Embed query text.\n",
            " |      \n",
            " |      Args:\n",
            " |          text: Text to embed.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Embedding.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(Chroma.from_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqSPNBU1Ap7H",
        "outputId": "834dc965-acce-4d3b-cbc8-be70bce140a3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method from_texts in module langchain_chroma.vectorstores:\n",
            "\n",
            "from_texts(texts: 'List[str]', embedding: 'Optional[Embeddings]' = None, metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, collection_name: 'str' = 'langchain', persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, client: 'Optional[chromadb.ClientAPI]' = None, collection_metadata: 'Optional[Dict]' = None, **kwargs: 'Any') -> 'Chroma' method of abc.ABCMeta instance\n",
            "    Create a Chroma vectorstore from a raw documents.\n",
            "    \n",
            "    If a persist_directory is specified, the collection will be persisted there.\n",
            "    Otherwise, the data will be ephemeral in-memory.\n",
            "    \n",
            "    Args:\n",
            "        texts: List of texts to add to the collection.\n",
            "        collection_name: Name of the collection to create.\n",
            "        persist_directory: Directory to persist the collection.\n",
            "        embedding: Embedding function. Defaults to None.\n",
            "        metadatas: List of metadatas. Defaults to None.\n",
            "        ids: List of document IDs. Defaults to None.\n",
            "        client_settings: Chroma client settings.\n",
            "        client: Chroma client. Documentation:\n",
            "                https://docs.trychroma.com/reference/js-client#class:-chromaclient\n",
            "        collection_metadata: Collection configurations.\n",
            "                                              Defaults to None.\n",
            "        **kwargs: Additional keyword arguments to initialize a Chroma client.\n",
            "    \n",
            "    Returns:\n",
            "        Chroma: Chroma vectorstore.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(vectorstore.as_retriever)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5lNL2WVB8yN",
        "outputId": "6382d1d5-9f43-4e3e-ca3f-c5276beca38a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method as_retriever in module langchain_core.vectorstores.base:\n",
            "\n",
            "as_retriever(**kwargs: 'Any') -> 'VectorStoreRetriever' method of langchain_chroma.vectorstores.Chroma instance\n",
            "    Return VectorStoreRetriever initialized from this VectorStore.\n",
            "    \n",
            "    Args:\n",
            "        **kwargs: Keyword arguments to pass to the search function.\n",
            "            Can include:\n",
            "            search_type (Optional[str]): Defines the type of search that\n",
            "                the Retriever should perform.\n",
            "                Can be \"similarity\" (default), \"mmr\", or\n",
            "                \"similarity_score_threshold\".\n",
            "            search_kwargs (Optional[Dict]): Keyword arguments to pass to the\n",
            "                search function. Can include things like:\n",
            "                    k: Amount of documents to return (Default: 4)\n",
            "                    score_threshold: Minimum relevance threshold\n",
            "                        for similarity_score_threshold\n",
            "                    fetch_k: Amount of documents to pass to MMR algorithm\n",
            "                        (Default: 20)\n",
            "                    lambda_mult: Diversity of results returned by MMR;\n",
            "                        1 for minimum diversity and 0 for maximum. (Default: 0.5)\n",
            "                    filter: Filter by document metadata\n",
            "    \n",
            "    Returns:\n",
            "        VectorStoreRetriever: Retriever class for VectorStore.\n",
            "    \n",
            "    Examples:\n",
            "    \n",
            "    .. code-block:: python\n",
            "    \n",
            "        # Retrieve more documents with higher diversity\n",
            "        # Useful if your dataset has many similar documents\n",
            "        docsearch.as_retriever(\n",
            "            search_type=\"mmr\",\n",
            "            search_kwargs={'k': 6, 'lambda_mult': 0.25}\n",
            "        )\n",
            "    \n",
            "        # Fetch more documents for the MMR algorithm to consider\n",
            "        # But only return the top 5\n",
            "        docsearch.as_retriever(\n",
            "            search_type=\"mmr\",\n",
            "            search_kwargs={'k': 5, 'fetch_k': 50}\n",
            "        )\n",
            "    \n",
            "        # Only retrieve documents that have a relevance score\n",
            "        # Above a certain threshold\n",
            "        docsearch.as_retriever(\n",
            "            search_type=\"similarity_score_threshold\",\n",
            "            search_kwargs={'score_threshold': 0.8}\n",
            "        )\n",
            "    \n",
            "        # Only get the single most similar document from the dataset\n",
            "        docsearch.as_retriever(search_kwargs={'k': 1})\n",
            "    \n",
            "        # Use a filter to only retrieve documents from a specific paper\n",
            "        docsearch.as_retriever(\n",
            "            search_kwargs={'filter': {'paper_title':'GPT-4 Technical Report'}}\n",
            "        )\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\n",
        "  \"SammyTime/plaything\",\n",
        "  revision=\"main\"  # tag name, or branch name, or commit hash\n",
        ")"
      ],
      "metadata": {
        "id": "h50gfTlVMm9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_api_key = getpass.getpass(\"Enter your HF Inference API Key:\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyI29P9iWKz6",
        "outputId": "aca2ed45-e9b8-4c90-e400-5d4b2e5dc7dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your HF Inference API Key:\n",
            "\n",
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "  model_name=model_name,\n",
        "  model_kwargs=model_kwargs,\n",
        "  encode_kwargs=encode_kwargs\n",
        ")\n",
        "llm = HuggingFaceEndpoint(repo_id='tiiuae/falcon-7b-instruct', huggingfacehub_api_token=inference_api_key)\n",
        "query_result = embeddings.embed_query(loader.load()[0].page_content)\n",
        "print(len(query_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458,
          "referenced_widgets": [
            "3a6417c4f6ea4447b2e2a353da394dd3",
            "9b75cb1f5af2434fa5602c931538d8bb",
            "33a4ca1c34ea4ae3a58a768875a8d39d",
            "809b5578dca04d078ecebd4da1dbc7d5",
            "c6145fa4a0cb4147a13553c8aa929a84",
            "3322f1bbb91d4f31b591d4fbf1ec78f5",
            "0bf1735155eb460390f83d888808a8c2",
            "551dd64a0294485395b82eaa876fecc5",
            "0453df6ab4fd4bf49b24fab950fca8ca",
            "1f3f382745574c5ebb7a10f7f3c6b679",
            "d469ac2406f14404b0b8ffd3dabad042",
            "a66f9e2f488746588882d8259f4ad507",
            "6a2a02b6734045d689803d2b4a49ef40",
            "85f9b0990e7441a8a5410a0595a4de98",
            "36c087eb62ba450398a1928159687992",
            "d8c7a0e117c04767adef43fa598ebe80",
            "c94f56e656294ad0b9ca8bd2e233bba8",
            "c4cb24dcad2344a280d4d2065708fc94",
            "7dbc49ce38e3482fb6ae5a3d1a6117d9",
            "6184c8281aec47e4ab839ac57ee43acd",
            "eb989689f33049128e71e43b9c96769c",
            "969fbbad4c5240c084d5e921e58d1ffb",
            "b0f0cdb2f3154b759d65609c85038076",
            "cff14181da4f49d9963876f4538574fd",
            "858bdccbae4d487a852add771fc3c534",
            "a12f1b07a85d46dbb9746e8648f2bb70",
            "801dab09da6a44f6a27474c2d44a7936",
            "2c692bb2c6c146f29be6398ccaa16316",
            "66e358059d9d450b8d1e9670579dc502",
            "f99a424d87e4420d988c660debc208c7",
            "f7490322b7334b0f843c7a01abca9372",
            "db889b10d69c47709ae8347394b71f4e",
            "5cfccdeb41124f2690441fa7da6d8b9e",
            "330757c735d2403e98c52db28a04b151",
            "1ae234eadc8548cbb2a5bc93f2f626c2",
            "fb2f58b1c5f548caacb88caf71477fd5",
            "dc27fb4c84be4f659fdf14eeeade184f",
            "e0ff3536e512413f85bcd7af765b532f",
            "1a36d2e8c20045f88759976c25ef8fc3",
            "e0f6180f2594400fa22d476ae53964ac",
            "efe3d91cd06e4cf78be930e07ce5045e",
            "ff7eae20b31549eeac225dd6ea2b2963",
            "37a93d81cf834fa7bd04cf1664f32192",
            "d10a5952d2084d0993d0d64901518a55",
            "44fcf2dd88f44e3ebae22ec6dcf09867",
            "447e4b173cb24711875c96179831d72d",
            "40ea3cac3da64ba18d0397ab577a8ef6",
            "6c3b82fd9ced48f9a0a6284c40f3b8c2",
            "e0e3491b66c2400f8d3776ca0448bc6b",
            "693d7f049ceb4e16a167d5b75ade2230",
            "127264cd65754a09b9d85552fd9f7734",
            "8aad639a43c34969936b7bbc131dd95b",
            "f9d3e19e9dd8492b9e5d6a2fab4c644f",
            "1190e31bced045daae3189e3df36f5c4",
            "d996897185084c28ac9659e1d3f18cb3",
            "75f7c9e75f7c495b96dbf09352b44085",
            "c35616c02a8f4aa999be23285711374c",
            "a7611be2672348ae9d974494b025655f",
            "71112178e84e4445bc9a676eb7b03b64",
            "4ae986132a41446ca4ccc456ed514679",
            "4259c392011c4f0f9f37ff607c23b402",
            "4ef29d21cdb741f583853a1e7c0df34a",
            "108905633bad438f9d1c56d3d59ada66",
            "066549e4baac4a0f971aab475e5d8126",
            "998ab6830a1d4ff6abaaca8c4bfe5f32",
            "c2efeb16676f4175b69f87caab74d404",
            "0e958d30446948c0aa4592905da7aad4",
            "c22864432490410582f8beff000063c4",
            "1110f78e69ac4523a5e09c977b689b1b",
            "7c823d1d7e82416d9d522bd4ee0609c1",
            "8fb0dc99be044b7aae6232e187489062",
            "19f2dea97d874635ab264649c4f33156",
            "4b08bd8951724b17a149797bb52dd426",
            "c02224d1ecaa47eabcffc06d2e76a4b4",
            "9361f1a372ba41d498f274797cb4418e",
            "13acbd27c78041edb9548435bb60d757",
            "afc58d36fd614928aaa1d5c379a2387e",
            "542702ed1b5142a0a8ff0f4d5a9f1bed",
            "9f684afab0954c76b5c5795ca28e9d95",
            "0c4ffbb402b64796b5e03c069868faa6",
            "db37a114c7ec45ff9106fd9eb32ba4e9",
            "231c5291ab4e4dbda1348daf839e4b3e",
            "e7575b8060e64b42a8664f26e23f3099",
            "01a62b01a55442b5875a75e2283005e4",
            "95891f421ea94f79ad7027c2e690c074",
            "1ade4d084c1d4f6fa81e2c0a0c255e57",
            "521d451cd7f64eebb38ac40c364a5a8b",
            "b54bf69607124043af90c6f0ea00ceeb",
            "b468c5bc5ca44eef92a9863b663030e3",
            "d01f4d455b854109b42419f9f6175911",
            "35f22e400bbe4c29b11a20cb31068b9f",
            "6f77ff91831a4bc2910c7602cf34d540",
            "27fb543bbc5a439c997f5b5354e4976b",
            "ac374e4ff8764962a5afa38f52aabc47",
            "edc3c0f8436a4088a14969fb5b126178",
            "a485ac8725bb44f6a67a695954c659af",
            "24657e3de7184db5a001a149d465674c",
            "8006f0c6ec1148c9965302180fa9fff0",
            "2fabaf02e1bf4e85af1b025474ff10d9",
            "5f8a5561cd7f47bfbe0c921d707bb7de",
            "3bda2c275ae64ca48db868e4a9dac694",
            "54426992ffec4c48ab5697175fc0705f",
            "3e1d5a7351fc40a18f5cb40aad865985",
            "e903cb5efc1343e0b002663249ec4696",
            "10cb6c7687c54adfb1976d2347b70926",
            "89fddbbce6e04482b356441d3904c3b7",
            "7d8b0f2a26af476f95018cc82c7d3329",
            "1ed29c54f1334687bf3adf02eb94655c",
            "fa4098466a3943599c18ca31b5a643fd",
            "5a73e36f8cf2493ba6f42c65433966cf",
            "6e8e70bc5a774228ac5f2d657b483f91",
            "c06d73103f434024ae23a8f4e720a9da",
            "94c813d5e8064669a996075ad09d5659",
            "5e5cf40a7ece45f28f446e218eaed0c3",
            "7670934882ec4cd3acf4936162eb2107",
            "0bb5d8f0b4164cbfbd7e64635864aaaf",
            "0af84b372fbb4565af809513c6eeb478",
            "ec0cc4bd7d6f4031b5c74e6d12c340f8",
            "dbf421555bdb48b4b2e0ae486902b38a",
            "75e3b3bbae0c4e97bc6b5ae12ac3d67e",
            "c8a9a007f53a4644a7933c7ea003be96"
          ]
        },
        "id": "pp-kt0S0obAt",
        "outputId": "d5811358-8b5d-4436-ec3c-849745adc1a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a6417c4f6ea4447b2e2a353da394dd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a66f9e2f488746588882d8259f4ad507"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0f0cdb2f3154b759d65609c85038076"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "330757c735d2403e98c52db28a04b151"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44fcf2dd88f44e3ebae22ec6dcf09867"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75f7c9e75f7c495b96dbf09352b44085"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e958d30446948c0aa4592905da7aad4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "542702ed1b5142a0a8ff0f4d5a9f1bed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b468c5bc5ca44eef92a9863b663030e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f8a5561cd7f47bfbe0c921d707bb7de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e8e70bc5a774228ac5f2d657b483f91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][:]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVIPLO3bohTW",
        "outputId": "57f6434b-c19f-4589-ab67-5398464edfee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Glyndŵr University Research Online  ',\n",
              " 'Conference Paper  ',\n",
              " 'Review of unmanned aircraft system technologies to enable ',\n",
              " 'beyond visual line of sight (BVLOS) operations  ',\n",
              " 'Davies, L., Bolam, R., Vagapov, Y. and Anuchin, A.  ',\n",
              " 'This is a paper presented at the 10th International Conference on Electrical Power Drive ',\n",
              " 'Systems ICEPDS 2018, Novocherkassk, Russia, 3 -6 October 2018 . ',\n",
              " 'Copyright of the author(s). Reproduced here with their permission and the permission of the ',\n",
              " 'conference  organisers.  ',\n",
              " 'Recommended citation:  ',\n",
              " 'Davies, L., Bolam, R., Vagapov, Y. and Anuchin, A. (2018) ‘Review of unmanned aircraft ',\n",
              " 'system technologies to enable beyond visual line of sight (BVLOS) operations’. In Proc. 10th ',\n",
              " 'International Conference on Electrical Power Drive Systems IC EPDS 2018, Novocherkassk, ',\n",
              " 'Russia, 3 -6 October 2018, pp. 1 -6. doi: 10.1109/ICEPDS.2018.8571665Abstract—The need to develop and deploy Beyond Visual ',\n",
              " 'Line of Sight (BVLOS) aerial vehicles has intensified over the ',\n",
              " 'last decade. As the demand for Unmanned Aircraft Systems ',\n",
              " '(UAS) has increased, so too has the regulations that surrounds ',\n",
              " 'the industry. Strict regulations are currently in place but ',\n",
              " 'differ from country to country. Due to these regulations ',\n",
              " 'BVLOS innovators have been posed the task of exploring the ',\n",
              " 'means of operating flight missions with the UAV out of the ',\n",
              " 'sight of the pilot. Autonomous flight capability is not only ',\n",
              " 'fundamental to BVLOS operations for UAS but also likely to ',\n",
              " 'have a significant impact on the future development of ',\n",
              " 'passenger carrying autonomous aircraft. This review explores ',\n",
              " 'the technologies that have been developed to date that enable ',\n",
              " 'BVLOS applications. BVLOS flight operations have the ',\n",
              " 'potential to open a huge area of commercial opportunity ',\n",
              " 'however, there remain many concerns about the current ',\n",
              " 'capabilities of UAS to detect and avoid manned andunmanned airborne hazards that may pose a significant safety ',\n",
              " 'risk.  ',\n",
              " 'Keywords —drones, unmanned aircraft system, BVLOS, ',\n",
              " 'autonomous aircraft  ',\n",
              " 'I.  INTRODUCTION  ',\n",
              " 'Accompanying the rapid increase of drone operations ',\n",
              " 'over the past few years has been a comparative increase in ',\n",
              " 'the regulations governing the industry. The main driver for ',\n",
              " 'which has been the safety of societies with respect to their ',\n",
              " 'populations, property and environment. This cautious ',\n",
              " 'approach has been very successful to date and in the UK, in ',\n",
              " 'common with many other European countries, amateur ',\n",
              " 'drone operations are only permitted to take place within the ',\n",
              " 'Visual Line of Sight (VLOS) of the Remote Pilot. This is ',\n",
              " 'commonly interpreted to mean up to 500m horizontally and ',\n",
              " '400ft (120m) vertically. For commercial UAV operators ',\n",
              " 'Extended Visual Line of Sight (EVLOS) operations beyond ',\n",
              " 'the aforementioned distances may also be permissible. ',\n",
              " 'Applications must be submitted to the Civil AviationAuthority (CAA) for EVLOS which include an acceptable ',\n",
              " 'safety case and the use of deployed observers. Operations ',\n",
              " 'Beyond Visual Line of Sight (BVLOS) may also be ',\n",
              " 'permitted if an approved method of aerial separation and ',\n",
              " 'collision avoidance is employed or alternatively the flights ',\n",
              " 'are made within segregated airspace under Instrument ',\n",
              " 'Flying Rules (IFR) and with Air Traffic Control (ATC) ',\n",
              " 'clearance [1]. Fig. 1 illustrates VLOS, EVLOS and BVLOS ',\n",
              " 'operations.  Recently many national governments have identified ',\n",
              " 'UAS as a key economic growth sector for technology and ',\n",
              " 'are keen to encourage its development. In June 2017 the ',\n",
              " 'Single European Sky Air traffic management Research ',\n",
              " 'Joint Undertaking (SESAR Joint Undertaking) released a ',\n",
              " 'blueprint aimed at making a strong and dynamic EU drone ',\n",
              " 'services market by introducing the concept of “U -Space” a ',\n",
              " 'low-level airspace for drone operations [3]. This airspace is ',\n",
              " 'intended to be in place by 2019 and extend vertically to150m. Drone operations within it are to be safe and ',\n",
              " 'automated for BVLOS operations. It has been predicted ',\n",
              " 'that the advent of BVLOS operations will herald a new ',\n",
              " 'boom in the drone industry [4].  ',\n",
              " 'It could be claimed that the first recorded BVLOS UAV ',\n",
              " 'mission was carried out by the Austrian army in 1849 with ',\n",
              " 'an attack on Venice using hot air balloons filled with ',\n",
              " 'explosives. [5] Since then the use of UAVs has increase ',\n",
              " 'substantially in both the military and commercial sectors. In ',\n",
              " 'the UK, BVLOS flights are more commonly conducted by ',\n",
              " 'the military normally under the guidance of the Military ',\n",
              " 'Aviation Authority (MAA), but that seems to be about the ',\n",
              " 'change as the UK Civil Aviation Authority has granted ',\n",
              " 'permission to the Defence Infrastructure Organisation ',\n",
              " 'Service Delivery Training (DIO SD TRG), to conduct a ',\n",
              " 'BVLOS test at the Salisbury Plain Training area to meet its ',\n",
              " 'military requirements [6], [7]. This form of approval for ',\n",
              " 'BVLOS flights could be applied to a wide and variednumber of government and public applications. There are ',\n",
              " 'quite a few scenarios where BVLOS could be executed ',\n",
              " 'efficiently and safely such as: package delivery, which has ',\n",
              " 'already been tested by Amazon; pipeline inspections that Review of Unmanned Aircraft System Technologies  ',\n",
              " 'to Enable Beyond Visual Line of Sight  ',\n",
              " '(BVLOS) Operations  ',\n",
              " 'Alecksey Anuchin  ',\n",
              " 'Moscow Power Engineering Institute  ',\n",
              " 'Moscow, Russia  Lee Davies  ',\n",
              " 'Glyndwr University  ',\n",
              " 'Wrexham, UK  ',\n",
              " 'Fig. 1. VLOS, EVLOS and BVLOS illustrated [2].  ',\n",
              " 'UAV Pilot Additional ObserverVLOS Flights EVLOS FlightsBVLOS Flights',\n",
              " 'Range of Remote ControlVisual Range',\n",
              " '978-1-5386 -4713 -4/18/$31.00 ©2018 IEEE  Yuriy Vagapov  ',\n",
              " 'Glyndwr University  ',\n",
              " 'Wrexham, UK  Robert Cameron Bolam  ',\n",
              " 'Glyndwr University  ',\n",
              " 'Wrexham, UK  2018 X International Conference on Electrical Power Drive Systems (ICEPDS)stretch over great distances; agriculture; search and rescue; ',\n",
              " 'policing and border control etc. [8] -[12]. BVLOS ',\n",
              " 'operations can arise from features on the landscape when ',\n",
              " 'VLOS mission encounter obstacles such as mountains, ',\n",
              " 'dense forests and cities. Fig. 2 demonstrates typical areas of ',\n",
              " 'application for VLOS and BVLOS operations.  ',\n",
              " 'It is apparent that BVLOS capability is becoming an ',\n",
              " 'essential requirement as companies strive to develop ',\n",
              " 'autonomous passenger and air freight systems. To achieve ',\n",
              " 'safe deployment a UAS will depend on 360 -degree radial ',\n",
              " 'technologies that allow the vehicle to be aware of its ',\n",
              " 'surroundings. The following text reviews the BVLOS ',\n",
              " 'situational awareness methodologies and technologies that ',\n",
              " 'are currently available or in development.  ',\n",
              " 'II.  FIRST PERSON  VIEW (FPV) AND DETECT  AND AVOID  ',\n",
              " 'TECHNOLOGIES  ',\n",
              " 'In 2017 Transport Canada issued their unprecedented ',\n",
              " 'permission to Ventus Geospatial to perform a BVLOS test. ',\n",
              " 'The test was conducted using a Skyranger UAV whichreached a distance of 1.4 miles from the operator and was ',\n",
              " 'fitted with a camera for a First -Person View (FPV) ',\n",
              " 'allowing the live feed to be fed back to a monitored display ',\n",
              " '[13]. For the test run a chase vehicle was also used as a ',\n",
              " 'back up to monitor its progress.  ',\n",
              " 'FPV is not an uncommon means of technology to use ',\n",
              " 'with applications of this nature, although it could be argued ',\n",
              " 'that it cannot and should not replace a pilot’s own visual ',\n",
              " 'range as there is more to BVLOS applications than merely ',\n",
              " 'having a visual layout of the surrounding area. Other ',\n",
              " 'technologies should also be implemented for a flight plan to ',\n",
              " 'be executed safely. According to the reports surrounding ',\n",
              " 'the Skyranger test flight, the UAV was not fitted with any ',\n",
              " 'detect and avoid technology but in further tests will use ',\n",
              " 'Automatic Dependent Surveillance – Broadcast (ADS -B), ',\n",
              " 'which is surveillance technology that allows an aircraft to ',\n",
              " 'determine its position via satellite navigation and then inturn broadcast it periodically enabling it to be monitored ',\n",
              " 'and tracked. [14]. This, however, is not without its ',\n",
              " 'problems, such as the security of the UAS. A paper ',\n",
              " 'published by Costin and Francillon [15] questioned this ',\n",
              " 'lack of security in relation to protocol and practical attacks. ',\n",
              " 'The research concluded that there is indeed an inherent ',\n",
              " 'insecurity to the commercial grade ADS -B design as it was ',\n",
              " 'missing the most basic of security protocols. Taking this ',\n",
              " 'into consideration however, one of the most recent ADS -B ',\n",
              " 'products has been used for BVLOS operations is the ',\n",
              " 'Ping20s which has been successfully used on a UAV. It ',\n",
              " 'was used in a successful night and day test which was ',\n",
              " 'performed by Australian company V -Tol Aerospace and UK based RelmaTech [16]. Presently the Ping20s is ',\n",
              " 'possibly the world’s smallest and affordable Mode S ADS -',\n",
              " 'B transponder and allows UAV’s to respond to Mode S ',\n",
              " 'radar [17] (Fig. 3). This UAV was also fitted with aGosHawk -II HD sensor and its integrated laser rangefinders ',\n",
              " 'can determine exact distance under all environmental ',\n",
              " 'conditions. It is also equipped with optical sensors for both ',\n",
              " 'night and daytime operations [18]. The need to be able to ',\n",
              " 'fly at night is an essential commodity in the drone industry ',\n",
              " 'and the development of this technology could pave the way ',\n",
              " 'for regulated night missions to become a reality.  ',\n",
              " 'There is also an obvious need for a UAV to be aware of ',\n",
              " 'its surroundings and aware of other air traffic by using ',\n",
              " 'detect and avoid technology. One such technology has been ',\n",
              " 'developed and a paper published by Balachandran et al. ',\n",
              " '[19]. The paper explores an approach that enables a ',\n",
              " 'multitude of aircraft to coordinate their own manoeuvres. ',\n",
              " 'This is achieved by each of the aircraft implicitly agreeing ',\n",
              " 'on the region of the airspace that they will be occupying at ',\n",
              " 'that time. This in turn has led to the construction of a ',\n",
              " 'feedback mechanism that can be executed in real time. Theplanning of this process assumes that all the aircraft will ',\n",
              " 'reside in their own region and it is this assumption that is ',\n",
              " 'crucial to ensure that no aircraft are able to occupy the ',\n",
              " 'same airspace. Information is shared between the aircraft in ',\n",
              " 'relation to when one aircraft speeds up or slows down and ',\n",
              " 'will then asses the likelihood of a collision. If an aircraft ',\n",
              " 'enters an adjacent zone occupied by another aircraft it will ',\n",
              " 'be required to enter a holding pattern until it decides that it ',\n",
              " 'is safe to proceed it is therefore much more suited to ',\n",
              " 'multirotor UAV’s than fixed wing craft. This decision -',\n",
              " 'making ability can also serve as a feedback mechanism. ',\n",
              " 'The conclusion raised in the paper states that the best Fig. 2. VLOS and BVLOS mission applications.  ',\n",
              " 'Fig. 3. Ping20s transponder [17].  ',\n",
              " 'Hobbyists',\n",
              " 'Sport',\n",
              " 'Real Estate',\n",
              " 'Cinematography Structural ',\n",
              " 'Inspections',\n",
              " 'Surveying',\n",
              " 'Mapping',\n",
              " 'Environmental ',\n",
              " 'Research',\n",
              " 'First ',\n",
              " 'RespondersSearch and Rescue',\n",
              " 'Package Delivery',\n",
              " 'Linear Inspection(Rail, Oil and Power)Border Patrol',\n",
              " 'Fish and GameVLOS BVLOSmethod would be to enforce separation between aircraft by ',\n",
              " 'using geo -fencing restraints.  ',\n",
              " 'III.  UAS T RAFFIC  MANAGEMENT  (UTM) S YSTEM  ',\n",
              " 'NASA has been a major contributor to the world of ',\n",
              " 'UAS and has explored and developed prototype ',\n",
              " 'technologies for a UAS Traffic Management (UTM) ',\n",
              " 'system [21]. It is thought that this will enable the ',\n",
              " 'integration requirements needed for safe and efficient low ',\n",
              " 'altitude applications to be performed [19]. The paper ',\n",
              " 'presented by Kopardekar et al. [21] proposed a concept of ',\n",
              " 'operations for the UTM model. However, flying drones and ',\n",
              " 'small UAV’s in a civilian airspace presents its own ',\n",
              " 'challenges, for example in the event that there is a need to ',\n",
              " 'avoid a forced landing due to collision or due to failings of ',\n",
              " 'an aircraft’s control system. Their research is based on ',\n",
              " 'lessons learned through aviation history and how they can ',\n",
              " 'implement that into present day aviation. They believe that ',\n",
              " 'it is expected that all UAS will have the ability to operatesafely in variable weather conditions and in both controlled ',\n",
              " 'and uncontrolled airspace due to the advancement in ',\n",
              " 'technologies. All UAS will stay clear of each other as well ',\n",
              " 'as manned aircraft and all UAV operators and systems will ',\n",
              " 'be required to have up to date awareness of traffic ',\n",
              " 'constraints from the ground upwards. The aims of the UTM ',\n",
              " 'model is to be flexible in certain areas but vigorously ',\n",
              " 'structured in other areas when it is required. It is a risk -',\n",
              " 'based model that is currently aimed at low risk ',\n",
              " 'environments and will eventually progress in to higher risk ',\n",
              " 'scenarios and environments.  ',\n",
              " 'One of the key attributes of NASA’s UAS UTM system ',\n",
              " 'design is that it would not require any human operators to ',\n",
              " 'monitor the vehicles closely at all times. It is proposed that ',\n",
              " 'in its fully developed form the system could be further ',\n",
              " 'developed to have the following autonomous programming ',\n",
              " 'characteristics that include; self -configuration, self -protection from airborne hazards, land hazards and self -',\n",
              " 'optimisation during the mission in relation to current and ',\n",
              " 'predicted weather conditions. NASA also hopes to deliver ',\n",
              " 'two types of UTM systems with one being a portable UTM ',\n",
              " 'system that can be transported between areas to support ',\n",
              " 'operations. Whilst the second proposed concept would be ',\n",
              " 'in constant availability for a geographical area. This would ',\n",
              " 'enable the possibility of BVLOS applications to be ',\n",
              " 'delivered safely within this area [20]. Working with NASA ',\n",
              " 'in this development is Gryphon Sensors who at present ',\n",
              " 'have developed a sensor system that detects, identifies and ',\n",
              " 'tracks UAS. By using their main product Skylight, it ',\n",
              " 'provides an integrated picture consisting of radar for long ',\n",
              " 'range detection, spectrum sensing, controllers transiting ',\n",
              " 'radio frequency signals and Electro -Optical/Infrared (EO/',\n",
              " 'IR) cameras for visual detection of potential hazards [22]. ',\n",
              " 'Sense and avoid technologies are a must and arefundamental part of any equipment that is to be used for ',\n",
              " 'BVLOS applications.  ',\n",
              " 'IV .  RADAR  FOR UAS A PPLICATIONS  ',\n",
              " 'Radar is a prerequisite for UTM applications for ',\n",
              " 'unmanned aircraft. One of the most notable is the Foretem ',\n",
              " 'DroneHunter UAV (Fig. 4), which operates a BVLOS as a ',\n",
              " 'defence for day and night aerial security and boast as being ',\n",
              " 'the first counter drone system that can operate BLOS ',\n",
              " '(Beyond Line of Sight) [23].  The UAV is equipped with a novel piece of hardware ',\n",
              " 'called the Fortem TrueView radar model R20 and is based ',\n",
              " 'on radar technology used by the US department of defence ',\n",
              " 'drone programme. It provides the pilot the ability to detect ',\n",
              " 'objects from the air at long ranges to enhance the avoidance ',\n",
              " 'of other aircraft, aerial objects and other structures. One of ',\n",
              " 'the main additions of this device is the option for complete ',\n",
              " 'end to end integration which in turn allows for command ',\n",
              " 'and controlled autopilots [24]. It is also proposed thatautopilots will be able to execute mission safely even in ',\n",
              " 'more crowded spaces due to TrueView Radar as it can ',\n",
              " 'detect obstacles in its surroundings with sufficient time to ',\n",
              " 'determine the potential of an incident and then in turn stay ',\n",
              " 'well clear by manoeuvring to a safe place or to a safe ',\n",
              " 'distance.  ',\n",
              " 'As well as the Foretem TrueView radar, Sematica ',\n",
              " 'Aerospace have developed the Zeus Radar System that has ',\n",
              " 'been specifically designed for UAS [25]. The system has ',\n",
              " 'been described to enhance situational awareness of any air ',\n",
              " 'bound craft entering the nearby airspace by using state of ',\n",
              " 'the art solid state radar and advanced signal processing ',\n",
              " 'techniques. Solid state radar has the ability to conduct ',\n",
              " '‘sweeps’ that can be adjusted in real time by the operator ',\n",
              " 'and embodies a range of different signals can be employed ',\n",
              " 'for more efficient signal processing [26]. This type of radar ',\n",
              " 'can use Doppler radar as well as pulsed radar without theneed for extra equipment so that it cannot only see objects ',\n",
              " 'within its airspace but also calculate and determine if the ',\n",
              " 'objects are moving. Although not a new technique the fact ',\n",
              " 'that it has been developed and engineered for UAS means ',\n",
              " 'that BVLOS could be one step closer.  ',\n",
              " 'Another company that has been working with NASA to ',\n",
              " 'develop sense and avoid (SAA) systems is Vigilant ',\n",
              " 'Aerospace who have completed successful testing of its ',\n",
              " 'new and recently developed FlightHorizon detect and ',\n",
              " 'avoidance system [27].  ',\n",
              " 'This software provides the operator and autopilots with ',\n",
              " 'complete situational awareness, detect and avoid system. ',\n",
              " 'By gathering data from various sources such as aviation ',\n",
              " 'transponders, ground based radar pulses and air traffic ',\n",
              " 'warnings. Vigilant Aerospace also incorporated an ',\n",
              " 'exclusive NASA patent software, which forms the ',\n",
              " 'backbone of the FlightHorizon product. The invention and ',\n",
              " 'patent by Arteaga [28] which is basically an ADS -B systemdetails that traffic information will be included in the ',\n",
              " 'transmission and through telemetry communication that is ',\n",
              " 'transmitted to a remote ground system. The invention goes ',\n",
              " 'Fig. 4. Foretem DroneHunter in action [23].further to propose the methods for displaying a general ',\n",
              " 'layout of aviation traffic information in possibly three or ',\n",
              " 'four-dimensional trajectories using an industry standard ',\n",
              " 'Earth Browser for heightened situational awareness and an ',\n",
              " 'enhanced visual range of possible traffic and obstacles in its ',\n",
              " 'flight path. It is also claimed that the novel invention can ',\n",
              " 'enable and enhance visual acquisition of traffic and traffic ',\n",
              " 'alerts [28].  ',\n",
              " 'V.  BVLOS M ISSIONS  AND ARTIFICIAL  INTELLIGENCE  (AI) ',\n",
              " 'In France BVLOS has been permitted since 2012 and ',\n",
              " 'the first BVLOS application test was successfully ',\n",
              " 'completed for inspecting power lines, by Delair -Tech who ',\n",
              " 'flew a UAV for over 30 miles using a 3G wireless network ',\n",
              " 'to guide the drone (Fig. 5). The company were granted a ',\n",
              " 'specific flight corridor in which conducted the test flight. ',\n",
              " 'Although the flight was conduct via autopilot, two pilots ',\n",
              " 'were present at the start and two pilots were present at thelanding site. Using the 3G network allowed for real -time ',\n",
              " 'communication from any distance as long as there was 3G ',\n",
              " 'coverage [29].  ',\n",
              " '2017 saw Israel step up its involvement in the BVLOS ',\n",
              " 'UAS sector and has recently granted full permission for ',\n",
              " 'BVLOS flights. The award was given by the Civil Aviation ',\n",
              " 'Authority of Israel (CAAI), to Airobotics who have ',\n",
              " 'developed a UAV that can achieve and execute missions ',\n",
              " 'safely without the aid of a pilot (Fig. 6). On -board is ',\n",
              " 'Airobotics own computer software which also incorporates ',\n",
              " 'Artificial Intelligence (AI) which is programmed to make ',\n",
              " 'decisions and execute actions that are usually performed by ',\n",
              " 'a human pilot [30]. The BVLOS platform is based on three ',\n",
              " 'parts. The first component was the UAV, named ',\n",
              " '“Optimus”, which is a drone that is capable of flying thirty -',\n",
              " 'minute missions whilst being equipped with a one -kilogram ',\n",
              " 'payload. The second component is a completely unmanned, ',\n",
              " 'automated airbase from which the UAV can be launchedfrom and also lands on. The third and final piece and the ',\n",
              " 'most important is the software and the AI software, which ',\n",
              " 'enables operators to use the software easily and manage ',\n",
              " 'missions just with one click [31].  ',\n",
              " 'This may sound as though the problem that was once ',\n",
              " 'facing the drone industry has been solved, however the use ',\n",
              " 'of AI itself presents problems of its own. AI itself is a ',\n",
              " 'controversial topic for both industry and politics. Keeping ',\n",
              " 'AI, or narrow AI, which is purely focused on autonomous ',\n",
              " 'drone navigation, at a level that is beneficial for the good of ',\n",
              " 'mankind is hotly debated and motivates many research ',\n",
              " 'areas although flight safety is always the key element to be considered. The goal for most research is to create general ',\n",
              " 'AI that far outgrows the relative conformity if narrow AI ',\n",
              " '[31]. Currently the AI that we are living with are neural ',\n",
              " 'networks and machine learning algorithms that are used in ',\n",
              " 'everyday common devices [31]. A main concern is for ourown preservation as it is feared that AI could at some point ',\n",
              " 'become intelligent enough to replace humans and become ',\n",
              " 'part of a technological singularity. Indeed this is a situation ',\n",
              " 'some may even welcome as they see AI as a panacea for ',\n",
              " 'civilisation [32] even though AI might outperform humans ',\n",
              " 'at every cognitive task and risks rendering us obsolete [31]. ',\n",
              " 'AI will undoubtedly have a major impact on people’s lives, ',\n",
              " 'but the benefits are undeniable.  ',\n",
              " 'VI.  UAS S ENSOR  FUSION  ',\n",
              " 'Sensory communication with any UAS is paramount to ',\n",
              " 'operating beyond the pilots’ field of vision. A study into ',\n",
              " 'potential sensory appliances has been presented by Zhahir ',\n",
              " 'et al. [34] and looked at the current development of UAV ',\n",
              " 'sense and avoid systems. One possible theory presented as ',\n",
              " 'a possible way to achieve safe BVLOS applications, was to ',\n",
              " 'equip an UAV with electro -optical sensors combined with ',\n",
              " 'radar and infrared sensory capabilities. However, badweather or overcast and cloudy conditions could affect the ',\n",
              " 'performance at object and hazard identification as the ',\n",
              " 'sensors rely on good light to be able to work at full ',\n",
              " 'capacity. Another possibility discussed was ‘sensor fusion’, ',\n",
              " 'enabling multiple sensory tasks on a UAV platform to be ',\n",
              " 'performed simultaneously to enhance hazard detection and ',\n",
              " 'minimise flight risks. Ramasamy et al. [35] details a ',\n",
              " 'successful test using sensor fusion. The research ',\n",
              " 'successfully produced a simulated study of sensor fusion ',\n",
              " 'which combines natural inspired sensors and non -',\n",
              " 'cooperative sensors. The algorithm that was used by the ',\n",
              " 'researchers to achieve this is known as track to track fusion ',\n",
              " 'and is based on Boolean decision logic data structure that ',\n",
              " 'can evaluate and solve issues such as limited information of ',\n",
              " 'the environment or partial loss of transmitted information.  ',\n",
              " 'The UAV platform is essential for military applications ',\n",
              " 'and its role in conflict and congested zones cannot beunderestimated. Small unmanned aircraft embark upon ',\n",
              " 'intelligence gathering missions via reconnaissance and ',\n",
              " 'surveillance and BVLOS is an essential component. One ',\n",
              " 'example of the most state of the Art recognisance UAV that ',\n",
              " 'has been developed for BVLOS missions is the military’s ',\n",
              " 'Black Hornet Nano [36] (Fig. 7).  ',\n",
              " ' Fig. 5. Delair Tech BVLOS for power line inspection applications [29].  ',\n",
              " 'Fig. 6. Airobotics autonomous BVLOS system [33].This small, compact UAV is fitted with multi -sensory ',\n",
              " 'capability and has an integrated video stream data ink ',\n",
              " 'where images can be viewed in real time. Part of the UAS ',\n",
              " 'ability to perform BVLOS missions is that has the capacity ',\n",
              " 'to be programmed with a pre -planned route using GPS and ',\n",
              " 'can also be used in FPV with a maximum range of 1.5km ',\n",
              " 'distance between the operator and the UAV [36]. In ',\n",
              " 'comparison larger military UAS rely on satellite ',\n",
              " 'communication to operate rather than a direct flowing radio ',\n",
              " 'link. The military have further developed a system that can ',\n",
              " 'detect other aircraft so that they may be targeted by air to ',\n",
              " 'air missiles. The system known as Active Electronically ',\n",
              " 'Scanned Array (AESA) radar, which is also known as an ',\n",
              " 'active phase array radar, which operates by emitting a pulse ',\n",
              " 'signal from a transmitter that in turn is received by an ',\n",
              " 'onboard antenna that receives amplified echoes of any ',\n",
              " 'objects in the vicinity.  ',\n",
              " 'Texas Instruments, in 2016 discussed the benefits ofdeveloping a low latency design for video enabled drones ',\n",
              " '[37]. One of the main features that a piloted UAV requires ',\n",
              " 'would be an onboard camera as well as a range of other ',\n",
              " 'SAA instruments. The needs of the camera are directly ',\n",
              " 'linked to the needs of the UAV. A low power consumption ',\n",
              " 'rate is necessary so that it does not impact on the UAV’s ',\n",
              " 'power supply and just as important a low latency data ',\n",
              " 'collection design is needed. As with any optical capturing ',\n",
              " 'instrument a higher frame rate will lead to lower capture ',\n",
              " 'time. This is important when needing to transmit images ',\n",
              " 'quickly as the compression and encoding times are greatly ',\n",
              " 'reduced. Using industry standard compression format of ',\n",
              " 'H.264 will enable this encoding to be initiated quicker with ',\n",
              " 'limited visible loss in quality of the image. The research ',\n",
              " 'conducted by Texas Instruments proposes to fully utilise ',\n",
              " 'low latency and H.264 compression. This is achieved by ',\n",
              " 'introducing the concept of “slices” composed of severalindependently encoded macroblocks which can thus be ',\n",
              " 'decoded by itself without any interference of the data ',\n",
              " 'capture. This would also naturally decrease the render time ',\n",
              " 'of any image. To permit the drone to capture video the ',\n",
              " 'camera must be interfaced to the digital processor using one ',\n",
              " 'of the dedicated camera interfaces. The feed is then ',\n",
              " 'transmitted to a ground control unit using either 2.4 or ',\n",
              " '5.8GHz Wi -Fi which in turn will be shown on a display ',\n",
              " 'unit for the operator to view the FPV image.  ',\n",
              " 'The use of video capturing sensors is a multi -faceted ',\n",
              " 'problem, as with any broadcast a reliable transmission ',\n",
              " 'signal is a must. As the wireless communication link must be able to cope with long range transmission and reception. ',\n",
              " 'The research looks at several ways in which this can be ',\n",
              " 'achieved with either antenna diversity, maximum ratio ',\n",
              " 'combing (MRC) and Multi -Input and Multi Output ',\n",
              " '(MIMO) and finally rate adaption. This would obviouslydepend on which wireless network would be available in ',\n",
              " 'the area at the time of where the operation is to be flown.  ',\n",
              " 'VII.  CONCLUSION  ',\n",
              " 'The technology for safe and efficient BVLOS mission ',\n",
              " 'completion is already available and seems likely to become ',\n",
              " 'common place. There are however, a number of factors ',\n",
              " 'which still need to be addressed to ensure the maximum ',\n",
              " 'safety for BVLOS operations. The most important of which ',\n",
              " 'is UAS communications technology supporting command ',\n",
              " 'and control, navigation, surveillance, situation awareness ',\n",
              " 'and the integration with Air Traffic Management (ATM) ',\n",
              " 'systems for remotely piloted and autonomous aircraft. ',\n",
              " 'Development in these technologies and their ',\n",
              " 'miniaturisation remains an enabler of future UAS BVLOS ',\n",
              " 'capabilities.  ',\n",
              " 'The regulations surrounding BVLOS are currently ',\n",
              " 'subject to revision as the new European airspace U -Space ',\n",
              " 'develops. As BVLOS technology grows and improves so ',\n",
              " 'too should the airworthiness regulations to facilitate andguide the industry sector and the deployment of drones in ',\n",
              " 'our society.  ',\n",
              " 'Autonomous flight capability is not only fundamental to ',\n",
              " 'BVLOS operations for UAS but also likely to have a ',\n",
              " 'significant impact on the future development of passenger ',\n",
              " 'carrying autonomous aircraft. Minimising the Human ',\n",
              " 'Factor in aircraft flight has always been a major safety goal ',\n",
              " 'and also provides the potential to reduce operational costs. ',\n",
              " 'It would therefore appear that the benefits of achieving ',\n",
              " 'BVLOS capabilities are likely to outweigh the risks that are ',\n",
              " 'currently attributed to an UAS flying beyond an operator’s ',\n",
              " 'line of sight.  ',\n",
              " 'REFERENCES  ',\n",
              " '[1] Civil Aviation Authority. (2015, March 31). CAP 722 Unmanned ',\n",
              " 'Aircraft System Operations in UK Airspace —Guidance . (6th ed.) ',\n",
              " '[Online]. Available: https://publicapps.caa.co.uk/docs/33/CAP%',\n",
              " '20722%20Sixth%20Edition%20March%202015.pdf  ',\n",
              " '[2] C. Stocker, R. Bennett, F. Nex, M. Gerke, and J. Zevenbergen,“Review of the current state of UAV regulations,” Remote Sensing , ',\n",
              " 'vol. 9, no. 5, article 459, 2017.  ',\n",
              " '[3] European Commission. Press Release. (2017, June 16). Aviation: ',\n",
              " 'Commission is Taking the European Drone Sector to New Heights . ',\n",
              " '[Online]. Available: http://europa.eu/rapid/press -release_IP -17-',\n",
              " '1605_en.pdf  ',\n",
              " \"[4] A. Perlman (2017, Feb. 16). “Inside BVLOS, the drone industry's \",\n",
              " 'next game -changer”, UAV Coach . [Online]. Available: https://',\n",
              " 'uavcoach.com/inside -bvlos  ',\n",
              " '[5] Imperial War Museums. (2018, Jan. 30). A Brief History of Drones . ',\n",
              " '[Online]. Available: http://www.iwm.org.uk/history/a -brief -history -',\n",
              " 'of-drones  ',\n",
              " '[6] Civil Aviation Authority, CAP 1612 Airspace Change Decision: ',\n",
              " 'Beyond Visual Line of Sight Unmanned Aircraft Systems Operations ',\n",
              " 'in EG D128 – Everleigh , Gatwick: CAA, 2017.  ',\n",
              " '[7] Defence Infrastructure Organisation. (2017, Dec. 6). Proposal for ',\n",
              " 'Beyond Visual Line of Sight Formal (BVLOS) Remotely Piloted AirSystems (RPAS) Operations in EDG 128 – Everleigh . [Online]. ',\n",
              " 'Available: https://www.caa.co.uk/uploadedFiles/CAA/Content/',\n",
              " 'Standard_Content/Commercial_industry/Airspace/',\n",
              " 'Airspace_change/20171016 -FORMAL%20PROPOSAL%20FOR%',\n",
              " 'Fig. 7. Black Hornet Nano [38].20BVLOS%20RPAS%20OPERATIONS%20IN%20D128%',\n",
              " '20EVERLEIGH.pdf  ',\n",
              " '[8] H. Gonzalez -Jorge, J. Martinez -Sanchez, M. Bueno, and P. Arias, ',\n",
              " '“Unmanned aerial systems for civil applications: A review,” Drones , ',\n",
              " 'vol. 1, no. 1, article 2, 2017.  ',\n",
              " '[9] D. Day, “Drones for transmission infrastructure inspection and ',\n",
              " 'mapping improve efficiency,” Natural Gas and Electricity , vol. 33, ',\n",
              " 'no.12, pp. 7 –11, July 2017.  ',\n",
              " '[10] M. Pappota, and R.J. de Boera, “The integration of drones in today’s ',\n",
              " 'society,” Procedia Engineering , vol. 128, pp. 54 -63, 2015.  ',\n",
              " '[11] J.-L. Liardon, L. Hostettler, L. Zulliger, K. Kangur, N.G. Shaik, and ',\n",
              " 'D.A. Barry, “Lake imaging and monitoring aerial drone,” ',\n",
              " 'HardwareX , 2018, doi: https://doi.org/10.1016/j.ohx.2017.10.003  ',\n",
              " '[12] V.E. Hovstein, A. Sægrov, and T.A. Johansen, “Experiences with ',\n",
              " 'coastal and maritime UAS BLOS operation with phased -array ',\n",
              " 'antenna digital payload data link,” in Proc. Int. Conf. on UnmannedAircraft Systems (ICUAS) , Orlando, FL, USA, 27 -30 May 2014, pp. ',\n",
              " '261-266. ',\n",
              " '[13] J. Plaza (2017, March 29). “First commercial drone flight conducted ',\n",
              " 'beyond visual line of sight in Canada,” Commercial UAV News . ',\n",
              " '[Online]. Available: https://www.expouav.com/news/latest/first -',\n",
              " 'commercial -drone -flight -conducted -beyond -visual -line-sight -canada  ',\n",
              " '[14] J. Zimmerman (2013, Jan. 17). “ADS -B 101: What it is and why you ',\n",
              " 'should care,” Air Facts Journal . [Online]. Available: https://',\n",
              " 'airfactsjournal.com/2013/01/ads -b-101-what -it-is-and-why-you-',\n",
              " 'should -care ',\n",
              " '[15] A. Costin, and A. Francillon, “Ghost in the Air(Traffic): On ',\n",
              " 'insecurity of ADS -B protocol and practical attacks on ADS -B ',\n",
              " 'devices,” Black Hat , July 2012. [Online]. Available: https://',\n",
              " 'media.blackhat.com/bh -us-12/Briefings/Costin/',\n",
              " 'BH_US_12_Costin_Ghosts_In_Air_WP.pdf  ',\n",
              " '[16] V-Tol. (2017, Dec. 21). V -Tol Conducts Advanced BVLOS ADS -B ',\n",
              " 'Equipped Flight Operations . [Online]. Available: http://v -tol.com/v -tol-conducts -advanced -bvlos -ads-b-equipped -flight -operations  ',\n",
              " '[17] uAvionix. (2018). Ping20S . [Online]. Available: https://',\n",
              " 'www.uavionix.com/products/ping20s  ',\n",
              " '[18] Lotus Aviation Technology (2018). Electro Optic Gimbal . [Online]. ',\n",
              " 'Available: http://www.lotusaviation.com/goshawk_ii_hd.php.  ',\n",
              " '[19] S. Balachandran, C. Munoz, and M. Consiglio, “Implicitly ',\n",
              " 'coordinated detect and avoid capability for safe autonomous ',\n",
              " 'operation of small UAS,” in Proc. 17th AIAA Aviation Technology, ',\n",
              " 'Integration, and Operations Conference , Denver, Colorado, 5 -9 June ',\n",
              " '2017, pp.1 -10. ',\n",
              " '[20] M. Johnson, J. Jung, J. Rios, J. Mercer, J. Homola, T. Prevot, D. ',\n",
              " 'Mulfinger, and P. Kopardekar, “Flight test evaluation of an ',\n",
              " 'unmanned aircraft system traffic management (UTM) concept for ',\n",
              " 'multiple beyond -visual -line-of-sight operations,” in Proc. 12th USA/',\n",
              " 'Europe Air Traffic Management Research and Development ',\n",
              " 'Seminar , Seattle, WA, USA, 26 -30 Jun. 2017, pp. 1 -10.[21] P. Kopardekar, J. Rios, T. Prevot , M. Johnson, J. Jung, and J.E. ',\n",
              " 'Robinson III, “Unmanned aircraft system traffic management (UTM) ',\n",
              " 'concept of operations,” in Proc. 16th AIAA Aviation Technology, ',\n",
              " 'Integration, and Operations Conference , Washington, DC, USA, 13 -',\n",
              " '17 June 2016, pp. 1 -16. ',\n",
              " '[22] Gryphon Sensors. (2017). What Is Skylight? [Online]. Available: ',\n",
              " 'http://gryphonsensors.com/products/#product -showcase  [23] Fortem Technologies. (2017). Autonomous Counter -UAV System. ',\n",
              " 'Fortem DroneHunter.  [Online]. Available: http://',\n",
              " 'www.fortemtech.com/dronehunter.html  ',\n",
              " '[24] Fortem Technologies. (2017). Small Long -Range Radar for UAVs . ',\n",
              " 'Fortem TrueView . [Online]. Available: http://fortemtech.com/',\n",
              " 'r20.html  ',\n",
              " '[25] Seamatica Aerospace. (2018). Zeus Radar System . [Online]. ',\n",
              " 'Available: http://seamatica.weebly.com/zeus -radar -system.html  ',\n",
              " '[26] T. Burden (2018, Feb. 26). “A new wave of marine radar,” West ',\n",
              " 'Marine.  [Online]. Available: https://www.westmarine.com/WestAdvisor/New -Radar -Technology  ',\n",
              " '[27] C. Rees (2017, Jan. 30). “New detect -and-avoid system for drones ',\n",
              " 'completes BLOS flight tests,” Unmanned Systems Technology . ',\n",
              " '[Online]. Available: http://',\n",
              " 'www.unmannedsystemstechnology.com/2017/01/vigilant -aerospace -',\n",
              " 'completes -blos-uas-testing -nasa-flight -research -center  ',\n",
              " '[28] R. Arteaga, “Automatic dependent surveillance broadcast (ADS -B) ',\n",
              " 'system for ownership and traffic situational awareness,” US Patent ',\n",
              " '9405005 B1, 2016.  ',\n",
              " '[29] Delair -Tech. Press Release. (2017, June 8). 1st in France: Drone ',\n",
              " 'Completes 30 miles BVLOS Flight via 3G Cell Network . [Online]. ',\n",
              " 'Available: http://delair.aero/wp -content/uploads/2017/06/Press -',\n",
              " 'Release_RTE_EN -1.pdf  ',\n",
              " '[30] C. Rees (2017, March 31). “Airobotics approved to fly fully -',\n",
              " 'automated BVLOS drones,” Unmanned Systems Technology . ',\n",
              " '[Online]. Available: http://',\n",
              " 'www.unmannedsystemstechnology.com/2017/03/airobotics -granted -',\n",
              " 'approval -fly-fully -automated -commercial -drones[31] Future of Life Institute. (2017). Benefits and Risks of Artificial ',\n",
              " 'Intelligence . [Online]. Available: https://futureoflife.org/background/',\n",
              " 'benefits -risks -of-artificial -intelligence  ',\n",
              " '[32] D. Galeon (2017, April 15). “Artificial intelligence is only dangerous ',\n",
              " 'if humans use it foolishly,” Futurism. [Online]. Available: https://',\n",
              " 'futurism.com/artificial -intelligence -only-dangerous -humans -use-',\n",
              " 'foolishly  ',\n",
              " '[33] G. Bazzolo. (2017, Apr 12). Investment Data: Airobotics from Israel ',\n",
              " 'gets the first world license to fly commercial drones fully automated. ',\n",
              " 'beBee . [Online]. Available: https://www.bebee.com/producer/',\n",
              " '@www -qudron -com/investment -data-airobotics -from -israel -gets-the',\n",
              " '-first-world -license -to-fly-commercial -drones -fully-automated  ',\n",
              " '[34] A. Zhahir, A. Razali, and M. Mohd Ajir, “Current development of ',\n",
              " 'UAV sense and avoid system,” IOP Conf. Series: Materials Science ',\n",
              " 'and Engineering , vol. 152, article. 012035, 2016.[35] S. Ramasamy, R. Sabatini, and A. Gardi, “Avionics sensor fusion for ',\n",
              " 'small size unmanned aircraft Sense -and-Avoid,” in Proc. IEEE Conf. ',\n",
              " 'Metrology for Aerospace (MetroAeroSpace) , Benevento, Italy, 29 -30 ',\n",
              " 'May 2014, pp. 271 -276. ',\n",
              " '[36] Aviassist. Commercial Drone Blog. (2017). The Opportunities and ',\n",
              " 'Challenges of Flying Beyond Line of Sight (BVLOS). [Online]. ',\n",
              " 'Available: https://www.aviassist.com.au/opportunities -challenges -',\n",
              " 'flying -drones -beyond -line-sight -bvlos  ',\n",
              " '[37] D. Barrett, and P. Desai (2016). Low-latency Design Considerations ',\n",
              " 'for Video -enabled Drones.  [Online]. Available: http://www.ti.com/',\n",
              " 'lit/wp/spry301/spry301.pdf  ',\n",
              " '[38] Wikipedia. (2017, Oct. 21). Black Hornet Nano . [Online]. Available;  ',\n",
              " 'https://en.wikipedia.org/wiki/Black_Hornet_Nano']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_texts(dataset['train'][:]['text'], embedding=embeddings)"
      ],
      "metadata": {
        "id": "c4O3q6iuZQgQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k':3})"
      ],
      "metadata": {
        "id": "k20nruodeU1o"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"\"\"\n",
        "Answer the following question using the context provided:\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nOU_Efspgdq1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([('human', message)])"
      ],
      "metadata": {
        "id": "Cjit2MFJex_O"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating chain to link retriever, prompt, and llm\n",
        "rag_chain = ({'context': retriever, \"question\": RunnablePassthrough()} | prompt | llm)"
      ],
      "metadata": {
        "id": "W1EanoSn0nZ8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke('tell me something intersting about unmaned drones')\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hrt9oC__3eCm",
        "outputId": "622e5d3c-8a42-4acc-a078-5ba72115c39f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unmanned drones, also known as \"drones\" or \"unmanned aerial vehicles,\" are remote-controlled aircraft that are often used for surveillance and reconnaissance. They can be operated from a safe and secure location, eliminating the need for a human pilot to be physically present at the scene. They are also known as \"unmanned aerial systems\" (UAS) and are often used for military purposes, as well as commercial applications such as aerial photography, surveying, and mapping.\n",
            "\n",
            "<p>Interesting fact:</p>\n",
            "\n",
            "In the United States, the Federal Aviation Administration (FAA) has implemented regulations to ensure the safe operation of UAS. The regulations require drone operators to register their UAS and follow a set of guidelines, including maintaining a safe distance from people and other aircraft, avoiding incursions into controlled airspace, and keeping their UAS away from sensitive locations and national security sites. The regulations also require UAS operators to keep their devices within visual range at all times and to be aware of their surroundings to avoid collision with other objects.</p>\n"
          ]
        }
      ]
    }
  ]
}